import os
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import datetime

# --- é…ç½®å€ ---
INPUT_FILE = '/Users/deepweay/Documents/github/deepseet/3ba5535a-aa16-4bf5-a3cb-c9901235153f.html'  # ä½ çš„æ–‡ä»¶å
OUTPUT_FILE = '/Users/deepweay/Documents/github/deepseet/Knowledge_Base_Import.md'

# --- æ™ºèƒ½åˆ†é¡é‚è¼¯ ---
def get_category_and_type(url, title):
    url = url.lower()
    title = title.lower()
    
    # 1. è¦–é »æµ (Videos)
    if any(x in url for x in ['youtube', 'youtu.be', 'bilibili', 'vimeo', 'xnxx', 'xvideos', 'pornhub']):
        return "ğŸ¥ è¦–é »åª’é«” (Videos)", "Video"
    
    # 2. åœ–ç‰‡/è¨­è¨ˆ (Images/Design)
    if any(x in url for x in ['pinterest', 'huaban', 'behance', 'artstation', 'pixabay', 'istock', 'imgur']) or \
       url.endswith(('.jpg', '.png', '.gif', '.jpeg')):
        return "ğŸ–¼ï¸ è¦–è¦ºéˆæ„Ÿ (Images)", "Image"
        
    # 3. æŠ€è¡“/ä»£ç¢¼/é›²æœå‹™ (Tech stack)
    if any(x in url for x in ['github', 'stackoverflow', 'csdn', 'google.com/cloud', 'console.cloud', 'aliyun', 'digitalocean', 'vps', 'cloudflare', 'python', 'api']):
        return "ğŸ’» æŠ€è¡“è»ç«åº« (Tech Stack)", "Tech"
        
    # 4. æ•¸å­—éŠæ°‘/å·¥å…· (Nomad Tools)
    if any(x in url for x in ['visa', 'ticket', 'flight', 'airbnb', 'map', 'sms', 'receive', 'wallet', 'crypto', 'binance', 'pay']):
        return "ğŸŒ æ•¸å­—éŠæ°‘ (Nomad Life)", "Tool"

    # 5. ç§‘å­¸/ç ”ç©¶ (Research/Bio) - é‡å°ä½ çš„è—¥ç†å­¸/åŒ–å­¸å…§å®¹
    if any(x in url for x in ['erowid', 'psychonautwiki', 'chemical', 'science', 'nature.com', 'ncbi', 'wiki']):
        return "ğŸ§ª é‚Šç·£ç§‘å­¸ (Research)", "Study"
    
    # 6. é»˜èªæ­¸é¡
    return "ğŸ“‚ ç¶œåˆæ­¸æª” (General)", "Web"

def parse_bookmarks(file_path):
    print("æ­£åœ¨åŠ è¼‰æ›¸ç±¤æ•¸æ“š...")
    with open(file_path, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f, 'html.parser')

    links = soup.find_all('a')
    structured_data = {}

    for link in links:
        url = link.get('href')
        title = link.get_text().strip()
        add_date = link.get('add_date')
        
        # è½‰æ›æ™‚é–“æˆ³
        try:
            date_str = datetime.datetime.fromtimestamp(int(add_date)).strftime('%Y-%m-%d')
        except:
            date_str = "Unknown"

        category, content_type = get_category_and_type(url, title)

        if category not in structured_data:
            structured_data[category] = []
        
        structured_data[category].append({
            'title': title,
            'url': url,
            'date': date_str,
            'type': content_type
        })
    
    return structured_data

def generate_markdown(data, output_path):
    print(f"æ­£åœ¨ç”ŸæˆçŸ¥è­˜åº«æ–‡ä»¶: {output_path} ...")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# ğŸ§  Digital Brain Knowledge Base\n\n")
        f.write("> ç”±è‡ªå‹•åŒ–è…³æœ¬ç”Ÿæˆï¼Œå·²æŒ‰å±¬æ€§åˆ†é¡ã€‚å¯ä»¥ç›´æ¥å°å…¥ Notionã€‚\n\n")

        # æŒ‰åˆ†é¡å¯«å…¥
        for category, items in data.items():
            f.write(f"## {category}\n\n")
            # å‰µå»º Markdown è¡¨æ ¼ï¼Œæ–¹ä¾¿ Notion è­˜åˆ¥ç‚º Database
            f.write("| Title | URL | Date | Type |\n")
            f.write("| --- | --- | --- | --- |\n")
            
            for item in items:
                # è™•ç†æ¨™é¡Œä¸­çš„è±ç·šï¼Œé˜²æ­¢ç ´å£è¡¨æ ¼
                clean_title = item['title'].replace('|', '-')
                f.write(f"| [{clean_title}]({item['url']}) | {item['url']} | {item['date']} | {item['type']} |\n")
            
            f.write("\n---\n\n")

# --- åŸ·è¡Œ ---
if __name__ == "__main__":
    data = parse_bookmarks(INPUT_FILE)
    generate_markdown(data, OUTPUT_FILE)