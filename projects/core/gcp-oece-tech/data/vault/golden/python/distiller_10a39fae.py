#!/usr/bin/env python3
"""
ğŸ”¥ Digital Assets Distiller V2.0 - æ ¸å¿ƒè’¸é¤¾å¼•æ“
æ•¸å­—é»ƒé‡‘æç…‰å™¨ - Gemini 3 Proé©…å‹•
"""

import os
import json
import time
import hashlib
from pathlib import Path
from datetime import datetime
import google.generativeai as genai
from tqdm import tqdm
import sys

# é…ç½®
API_KEY = os.getenv('API_KEY')
WAVE_ID = os.getenv('WAVE_ID', '1')
MODEL_NAME = os.getenv('MODEL_NAME', 'gemini-3-pro-preview')
BUDGET_LIMIT = float(os.getenv('BUDGET_LIMIT', '10'))
EXCHANGE_RATE = 35.5  # THB/USD

# ç›®éŒ„è¨­ç½®
INPUT_DIR = Path('/app/input')
OUTPUT_DIR = Path('/app/output')
CHECKPOINT_FILE = Path(f'/app/checkpoints/wave{WAVE_ID}.json')

class DigitalAssetsDistiller:
    def __init__(self):
        if not API_KEY:
            raise ValueError("âŒ API_KEYç’°å¢ƒè®Šé‡æœªè¨­ç½®ï¼")
        
        genai.configure(api_key=API_KEY)
        self.model = genai.GenerativeModel(MODEL_NAME)
        
        self.total_cost_usd = 0
        self.input_tokens = 0
        self.output_tokens = 0
        self.processed_docs = 0
        
        # åŠ è¼‰æª¢æŸ¥é»
        self.checkpoint = self.load_checkpoint()
        
        print(f"\nğŸ”¥ å•Ÿå‹•æ•¸å­—é»ƒé‡‘è’¸é¤¾å™¨ - Wave {WAVE_ID}")
        print(f"ğŸ’ æ¨¡å‹: {MODEL_NAME}")
        print(f"ğŸ’° é ç®—: ${BUDGET_LIMIT} USD (à¸¿{BUDGET_LIMIT * EXCHANGE_RATE:.0f} THB)")
        print(f"ğŸ“‚ è¼¸å…¥: {INPUT_DIR}")
        print(f"ğŸ“‚ è¼¸å‡º: {OUTPUT_DIR}\n")
    
    def load_checkpoint(self):
        """åŠ è¼‰æª¢æŸ¥é»"""
        if CHECKPOINT_FILE.exists():
            with open(CHECKPOINT_FILE, 'r') as f:
                data = json.load(f)
                self.total_cost_usd = data.get('total_cost_usd', 0)
                self.input_tokens = data.get('input_tokens', 0)
                self.output_tokens = data.get('output_tokens', 0)
                self.processed_docs = data.get('processed_docs', 0)
                print(f"ğŸ“ å¾æª¢æŸ¥é»æ¢å¾©: å·²è™•ç† {self.processed_docs} å€‹æ–‡æª”")
                return data.get('processed_files', [])
        return []
    
    def save_checkpoint(self):
        """ä¿å­˜æª¢æŸ¥é»"""
        CHECKPOINT_FILE.parent.mkdir(parents=True, exist_ok=True)
        checkpoint_data = {
            'wave_id': WAVE_ID,
            'processed_files': self.checkpoint,
            'total_cost_usd': self.total_cost_usd,
            'input_tokens': self.input_tokens,
            'output_tokens': self.output_tokens,
            'processed_docs': self.processed_docs,
            'timestamp': datetime.now().isoformat()
        }
        with open(CHECKPOINT_FILE, 'w') as f:
            json.dump(checkpoint_data, f, indent=2)
    
    def get_file_hash(self, filepath):
        """è¨ˆç®—æ–‡ä»¶å“ˆå¸Œ"""
        with open(filepath, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def estimate_cost(self, input_text, output_text):
        """ä¼°ç®—æˆæœ¬ï¼ˆåŸºæ–¼Geminiå®šåƒ¹ï¼‰"""
        # Gemini Proå®šåƒ¹ï¼ˆä¼°ç®—ï¼‰ï¼šè¼¸å…¥$0.0005/1K tokensï¼Œè¼¸å‡º$0.0015/1K tokens
        input_tokens = len(input_text) // 4
        output_tokens = len(output_text) // 4
        
        cost = (input_tokens / 1000 * 0.0005) + (output_tokens / 1000 * 0.0015)
        
        self.input_tokens += input_tokens
        self.output_tokens += output_tokens
        self.total_cost_usd += cost
        
        return cost, input_tokens, output_tokens
    
    def distill_document(self, doc_path):
        """è’¸é¤¾å–®å€‹æ–‡æª” - 4éšæ®µæç…‰"""
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            doc_name = doc_path.name
            
            # éšæ®µ1: å»é‡åˆ†æ
            stage1_prompt = f"""
            ä½ æ˜¯æ•¸å­—è³‡ç”¢è’¸é¤¾å¤§å¸«ã€‚åˆ†æé€™ä»½çè²´çš„æ•¸å­—é»ƒé‡‘æ–‡æª”ï¼Œåˆ¤æ–·å…¶ç¨ç‰¹åƒ¹å€¼ï¼š
            
            æ–‡æª”: {doc_name}
            å…§å®¹: {content[:3000]}
            
            è«‹è©•ä¼°ï¼š
            1. é€™ä»½æ–‡æª”çš„æ ¸å¿ƒåƒ¹å€¼æ˜¯ä»€éº¼ï¼Ÿ
            2. æ˜¯å¦åŒ…å«ç¨ç‰¹è¦‹è§£æˆ–ç½•è¦‹çŸ¥è­˜ï¼Ÿ
            3. çµ¦å‡ºåƒ¹å€¼è©•åˆ†ï¼ˆ0-10åˆ†ï¼‰
            """
            
            response1 = self.model.generate_content(
                stage1_prompt,
                generation_config={'temperature': 0.7}
            )
            value_analysis = response1.text
            
            # å¦‚æœåƒ¹å€¼ä½æ–¼5åˆ†ï¼Œè·³é
            if 'è©•åˆ†' in value_analysis or 'åˆ†æ•¸' in value_analysis:
                try:
                    score = float([s for s in value_analysis.split() if s.isdigit()][0])
                    if score < 5:
                        print(f"â­ï¸  è·³éä½åƒ¹å€¼æ–‡æª”: {doc_name} (è©•åˆ†: {score})")
                        return None
                except:
                    pass
            
            # éšæ®µ2: ç²¾è¯æå–
            stage2_prompt = f"""
            æå–é€™ä»½æ•¸å­—é»ƒé‡‘çš„æ ¸å¿ƒç²¾è¯ï¼š
            
            {content}
            
            è«‹æå–ï¼š
            - é—œéµçŸ¥è­˜é»
            - å¯¦ç”¨æŠ€å·§
            - çè²´ç¶“é©—
            - ç¨ç‰¹è¦‹è§£
            """
            
            response2 = self.model.generate_content(
                stage2_prompt,
                generation_config={'temperature': 0.3}
            )
            essence = response2.text
            
            # éšæ®µ3: é‚è¼¯æ•´åˆ
            stage3_prompt = f"""
            å°‡æå–çš„ç²¾è¯é€²è¡Œçµæ§‹åŒ–æ•´ç†ï¼š
            
            {essence}
            
            è¼¸å‡ºæ ¼å¼åŒ–çš„Markdownæ–‡æª”ã€‚
            """
            
            response3 = self.model.generate_content(
                stage3_prompt,
                generation_config={'temperature': 0.3}
            )
            structured = response3.text
            
            # éšæ®µ4: å‰µæ„æ“´å±•
            stage4_prompt = f"""
            åŸºæ–¼é€™äº›çè²´çŸ¥è­˜ï¼Œç”Ÿæˆå‰µæ–°æ€§æ“´å±•ï¼š
            
            {structured}
            
            æ·»åŠ ï¼š
            - å¯¦è¸å»ºè­°
            - æœ€ä½³å¯¦è¸
            - æ½›åœ¨æ‡‰ç”¨å ´æ™¯
            """
            
            response4 = self.model.generate_content(
                stage4_prompt,
                generation_config={'temperature': 0.9}
            )
            final = response4.text
            
            # è¨ˆç®—æˆæœ¬
            total_input = stage1_prompt + stage2_prompt + stage3_prompt + stage4_prompt
            total_output = value_analysis + essence + structured + final
            cost, in_tokens, out_tokens = self.estimate_cost(total_input, total_output)
            
            # ä¿å­˜çµæœ
            output_file = OUTPUT_DIR / f"distilled_{doc_name}"
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"# è’¸é¤¾å ±å‘Š: {doc_name}\n\n")
                f.write(f"## åƒ¹å€¼åˆ†æ\n{value_analysis}\n\n")
                f.write(f"## ç²¾è¯æå–\n{essence}\n\n")
                f.write(f"## çµæ§‹åŒ–å…§å®¹\n{structured}\n\n")
                f.write(f"## å‰µæ„æ“´å±•\n{final}\n\n")
                f.write(f"\n---\n")
                f.write(f"ğŸ’° æˆæœ¬: ${cost:.4f} USD (à¸¿{cost * EXCHANGE_RATE:.2f} THB)\n")
                f.write(f"ğŸ“Š Tokens: {in_tokens} in / {out_tokens} out\n")
            
            return {
                'file': doc_name,
                'cost_usd': cost,
                'tokens': {'input': in_tokens, 'output': out_tokens}
            }
            
        except Exception as e:
            print(f"âŒ è’¸é¤¾å¤±æ•—: {doc_name} - {e}")
            return None
    
    def run(self):
        """é‹è¡Œè’¸é¤¾æµç¨‹"""
        # ç²å–æ‰€æœ‰å¾…è™•ç†æ–‡æª”
        docs = list(INPUT_DIR.glob('**/*.md'))
        docs = [d for d in docs if self.get_file_hash(d) not in self.checkpoint]
        
        print(f"ğŸ“š æ‰¾åˆ° {len(docs)} å€‹å¾…è’¸é¤¾æ–‡æª”\n")
        
        with tqdm(total=len(docs), desc=f"Wave {WAVE_ID} è’¸é¤¾ä¸­") as pbar:
            for doc in docs:
                # æª¢æŸ¥é ç®—
                if self.total_cost_usd >= BUDGET_LIMIT:
                    print(f"\nğŸ’° é”åˆ°é ç®—ä¸Šé™ ${BUDGET_LIMIT}ï¼Œæš«åœè’¸é¤¾")
                    break
                
                result = self.distill_document(doc)
                
                if result:
                    self.processed_docs += 1
                    self.checkpoint.append(self.get_file_hash(doc))
                    self.save_checkpoint()
                    
                    pbar.set_postfix({
                        'cost': f'${self.total_cost_usd:.2f}',
                        'docs': self.processed_docs
                    })
                
                pbar.update(1)
                time.sleep(1)  # é¿å…APIé™æµ
        
        # æœ€çµ‚å ±å‘Š
        print(f"\nâœ… Wave {WAVE_ID} è’¸é¤¾å®Œæˆï¼")
        print(f"ğŸ“Š è™•ç†æ–‡æª”: {self.processed_docs}")
        print(f"ğŸ’° ç¸½æˆæœ¬: ${self.total_cost_usd:.4f} USD (à¸¿{self.total_cost_usd * EXCHANGE_RATE:.2f} THB)")
        print(f"ğŸ“ˆ Tokens: {self.input_tokens} in / {self.output_tokens} out\n")

if __name__ == '__main__':
    distiller = DigitalAssetsDistiller()
    distiller.run()
