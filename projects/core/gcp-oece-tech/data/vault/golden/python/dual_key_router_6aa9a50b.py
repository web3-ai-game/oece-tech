#!/usr/bin/env python3
"""
åŒKeyè½®æ›¿è·¯ç”±å™¨ - ä¼˜åŒ–å“åº”é€Ÿåº¦
"""

import logging
import asyncio
from datetime import datetime
from typing import Optional, Tuple
from enum import Enum
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from config import Config

logger = logging.getLogger(__name__)

class ModelType(Enum):
    """æ¨¡å‹ç±»å‹"""
    FLASH_LITE = "gemini-2.0-flash-lite"
    FLASH = "gemini-2.0-flash"
    FLASH_EXP = "gemini-2.0-flash-exp"
    PRO = "gemini-1.5-pro"

class KeyPool:
    """Keyæ± ç®¡ç†"""
    
    def __init__(self):
        # åŒKeyé…ç½® - éƒ½ç”¨flash-liteåšå¿«é€Ÿå“åº”
        self.keys = [
            {
                'name': 'KEY_1',
                'key': Config.GEMINI_KEY_PRIMARY,
                'models': [ModelType.FLASH_LITE, ModelType.FLASH, ModelType.FLASH_EXP, ModelType.PRO],
                'usage': {'daily': 0, 'hourly': 0},
                'last_used': None
            },
            {
                'name': 'KEY_2', 
                'key': Config.GEMINI_KEY_BACKUP,
                'models': [ModelType.FLASH_LITE],
                'usage': {'daily': 0, 'hourly': 0},
                'last_used': None
            }
        ]
        
        # è½®æ›¿ç´¢å¼•
        self.round_robin_index = 0
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._init_models()
        
        logger.info(f"ğŸ”„ DualKeyRouter initialized with {len(self.keys)} keys")
    
    def _init_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        for key_config in self.keys:
            genai.configure(api_key=key_config['key'])
            
            # ä¸ºæ¯ä¸ªkeyé…ç½®æ¨¡å‹
            key_config['model_instances'] = {}
            for model_type in key_config['models']:
                try:
                    if model_type == ModelType.FLASH_LITE:
                        model = genai.GenerativeModel(
                            model_name="gemini-2.0-flash-lite",
                            generation_config={
                                "temperature": 0.7,
                                "top_p": 0.8,
                                "top_k": 40,
                                "max_output_tokens": 8192,
                            },
                            safety_settings={
                                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                            }
                        )
                    elif model_type == ModelType.FLASH:
                        model = genai.GenerativeModel(
                            model_name="gemini-2.0-flash",
                            generation_config={
                                "temperature": 0.7,
                                "top_p": 0.8,
                                "top_k": 40,
                                "max_output_tokens": 8192,
                            }
                        )
                    elif model_type == ModelType.FLASH_EXP:
                        model = genai.GenerativeModel(
                            model_name="gemini-2.0-flash-exp",
                            generation_config={
                                "temperature": 0.7,
                                "top_p": 0.8,
                                "top_k": 40,
                                "max_output_tokens": 8192,
                            }
                        )
                    elif model_type == ModelType.PRO:
                        model = genai.GenerativeModel(
                            model_name="gemini-1.5-pro",
                            generation_config={
                                "temperature": 0.7,
                                "top_p": 0.8,
                                "top_k": 40,
                                "max_output_tokens": 8192,
                            }
                        )
                    
                    key_config['model_instances'][model_type] = model
                    logger.info(f"âœ… {key_config['name']} initialized {model_type.value}")
                    
                except Exception as e:
                    logger.error(f"âŒ Failed to init {model_type.value} for {key_config['name']}: {e}")
    
    def get_available_key(self, model_type: ModelType, is_owner: bool = False) -> Optional[dict]:
        """
        è·å–å¯ç”¨Key
        
        Args:
            model_type: éœ€è¦çš„æ¨¡å‹ç±»å‹
            is_owner: æ˜¯å¦ä¸ºOwner
            
        Returns:
            Keyé…ç½®æˆ–None
        """
        # Ownerå¯ä»¥ä½¿ç”¨æ‰€æœ‰æ¨¡å‹ï¼Œå…¶ä»–äººåªèƒ½ç”¨flash-lite
        if not is_owner and model_type != ModelType.FLASH_LITE:
            model_type = ModelType.FLASH_LITE
        
        # è½®æ›¿é€‰æ‹©Key
        for i in range(len(self.keys)):
            key_index = (self.round_robin_index + i) % len(self.keys)
            key_config = self.keys[key_index]
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ
            if model_type in key_config['models']:
                # æ£€æŸ¥ä½¿ç”¨é‡é™åˆ¶
                daily_limit = 1000 if model_type == ModelType.FLASH_LITE else 50
                if key_config['usage']['daily'] < daily_limit:
                    self.round_robin_index = (key_index + 1) % len(self.keys)
                    return key_config
        
        # å¦‚æœéƒ½æ»¡äº†ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        for key_config in self.keys:
            if model_type in key_config['models']:
                return key_config
        
        return None
    
    def generate_response(self, prompt: str, model_type: ModelType, is_owner: bool = False) -> Tuple[str, dict]:
        """
        ç”Ÿæˆå“åº”
        
        Args:
            prompt: è¾“å…¥æç¤º
            model_type: æ¨¡å‹ç±»å‹
            is_owner: æ˜¯å¦ä¸ºOwner
            
        Returns:
            (å“åº”æ–‡æœ¬, ä½¿ç”¨çš„keyä¿¡æ¯)
        """
        key_config = self.get_available_key(model_type, is_owner)
        if not key_config:
            raise Exception("No available key for model generation")
        
        model = key_config['model_instances'].get(model_type)
        if not model:
            raise Exception(f"Model {model_type.value} not available for key {key_config['name']}")
        
        try:
            # ç”Ÿæˆå“åº”
            response = model.generate_content(prompt)
            response_text = response.text
            
            # æ›´æ–°ä½¿ç”¨é‡
            key_config['usage']['daily'] += 1
            key_config['last_used'] = datetime.now()
            
            logger.info(f"âœ… Generated response via {key_config['name']} ({model_type.value})")
            
            return response_text, {
                'key_name': key_config['name'],
                'model_type': model_type.value,
                'daily_usage': key_config['usage']['daily']
            }
            
        except Exception as e:
            logger.error(f"âŒ Generation failed with {key_config['name']}: {e}")
            # å°è¯•ä¸‹ä¸€ä¸ªkey
            return self._fallback_generate(prompt, model_type, is_owner)
    
    def _fallback_generate(self, prompt: str, model_type: ModelType, is_owner: bool = False) -> Tuple[str, dict]:
        """é™çº§ç”Ÿæˆ"""
        # é™çº§åˆ°flash-lite
        if model_type != ModelType.FLASH_LITE:
            return self.generate_response(prompt, ModelType.FLASH_LITE, is_owner)
        
        raise Exception("All keys failed")

class DualKeyRouter:
    """åŒKeyè·¯ç”±å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.key_pool = KeyPool()
    
    def route_and_generate(self, message: str, is_group: bool, is_owner: bool) -> Tuple[str, dict]:
        """
        è·¯ç”±å¹¶ç”Ÿæˆå“åº”
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            is_group: æ˜¯å¦ç¾¤èŠ
            is_owner: æ˜¯å¦Owner
            
        Returns:
            (å“åº”æ–‡æœ¬, è·¯ç”±ä¿¡æ¯)
        """
        # æ„å»ºåŸºç¡€æç¤º
        base_prompt = """ä½ æ˜¯å°çˆ±åŒå­¦ï¼Œä¸€ä¸ªæ™ºèƒ½ã€å‹å¥½ã€åƒèŒä¸ç½‘ç»œä¸€æ ·è¿æ¥ä¸€åˆ‡çš„AIåŠ©æ‰‹ã€‚

è¯·ç”¨è‡ªç„¶ã€å‹å¥½çš„è¯­è°ƒå›å¤ç”¨æˆ·ã€‚å¦‚æœæ˜¯ç¾¤èŠï¼Œä¿æŒç®€æ´ï¼›å¦‚æœæ˜¯ç§èŠï¼Œå¯ä»¥æ›´è¯¦ç»†ã€‚

ç”¨æˆ·æ¶ˆæ¯: {message}

å°çˆ±:"""
        
        # ç­–ç•¥1: æ‰€æœ‰äººéƒ½ç”¨flash-liteå¿«é€Ÿå“åº”
        if is_group or not is_owner:
            model_type = ModelType.FLASH_LITE
            prompt = base_prompt.format(message=message)
            
        # ç­–ç•¥2: Ownerå•èŠç”¨é«˜çº§æ¨¡å‹
        else:
            # å…ˆç”¨flash-liteå¿«é€Ÿè¿æ¥
            if len(message) < 50:  # çŸ­æ¶ˆæ¯ç”¨lite
                model_type = ModelType.FLASH_LITE
                prompt = base_prompt.format(message=message)
            else:  # é•¿æ¶ˆæ¯æˆ–å¤æ‚ä»»åŠ¡ç”¨é«˜çº§æ¨¡å‹
                model_type = ModelType.FLASH_EXP  # æˆ–PRO
                prompt = """ä½ æ˜¯å°çˆ±åŒå­¦ï¼Œä¸€ä¸ªå¼ºå¤§çš„AIåŠ©æ‰‹ã€‚

è¯·è¯¦ç»†åˆ†æç”¨æˆ·çš„éœ€æ±‚å¹¶æä¾›ä¸“ä¸šçš„è§£å†³æ–¹æ¡ˆã€‚ä½ å¯ä»¥ï¼š
- åˆ†æå¤æ‚é—®é¢˜
- æä¾›ä»£ç ç¤ºä¾‹
- è®¾è®¡ç³»ç»Ÿæ¶æ„
- å›ç­”æŠ€æœ¯é—®é¢˜

ç”¨æˆ·æ¶ˆæ¯: {message}

å°çˆ±:""".format(message=message)
        
        # ç”Ÿæˆå“åº”
        response_text, key_info = self.key_pool.generate_response(
            prompt, model_type, is_owner
        )
        
        # è®°å½•è·¯ç”±ä¿¡æ¯
        route_info = {
            'is_group': is_group,
            'is_owner': is_owner,
            'model_used': key_info['model_type'],
            'key_used': key_info['key_name'],
            'daily_usage': key_info['daily_usage']
        }
        
        return response_text, route_info
