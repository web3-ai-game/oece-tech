#!/usr/bin/env python3
"""
ğŸ„ Gemini 2.5 Flash Lite æ™ºèƒ½è½®è¯¢å™¨
ç”¨äºå¤„ç†25kè¿ç¯æ¡¶è¯·æ±‚ï¼Œä¿è¯é«˜é€Ÿå“åº”
"""

import os
import time
import random
import asyncio
import hashlib
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import aiohttp
import redis.asyncio as redis
from dataclasses import dataclass
import json
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('GeminiRouter')

@dataclass
class APIKey:
    """APIå¯†é’¥é…ç½®"""
    key: str
    rpm_limit: int = 10  # æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶
    tpm_limit: int = 4000000  # æ¯åˆ†é’Ÿtokené™åˆ¶
    daily_limit: int = 1500  # æ¯æ—¥è¯·æ±‚é™åˆ¶
    last_used: float = 0
    request_count: int = 0
    daily_count: int = 0
    cooldown: float = 0.2  # å†·å´æ—¶é—´(ç§’)
    is_healthy: bool = True
    error_count: int = 0
    
    def can_use(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨è¯¥å¯†é’¥"""
        if not self.is_healthy:
            return False
        if time.time() - self.last_used < self.cooldown:
            return False
        if self.daily_count >= self.daily_limit:
            return False
        return True
    
    def use(self):
        """æ ‡è®°å¯†é’¥å·²ä½¿ç”¨"""
        self.last_used = time.time()
        self.request_count += 1
        self.daily_count += 1

class GeminiRouter:
    """Gemini APIæ™ºèƒ½è·¯ç”±å™¨"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        # æ¨¡å‹é…ç½®
        self.models = [
            "gemini-2.5-flash-8b-latest",  # æœ€è½»é‡ï¼Œé€‚åˆç®€å•å¯¹è¯
            "gemini-2.5-flash-latest",      # æ ‡å‡†ç‰ˆï¼Œå¹³è¡¡æ€§èƒ½
            "gemini-2.5-flash-002",         # ç¨³å®šç‰ˆ
        ]
        
        # ä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥
        api_keys_str = os.getenv('GEMINI_API_KEYS', '')
        self.api_keys: List[APIKey] = []
        for key in api_keys_str.split(','):
            if key.strip():
                self.api_keys.append(APIKey(key=key.strip()))
        
        # è½®è¯¢é…ç½®
        self.current_key_index = 0
        self.current_model_index = 0
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        
        # Redisè¿æ¥
        self.redis_url = redis_url
        self.redis_client: Optional[redis.Redis] = None
        
        # é€Ÿç‡é™åˆ¶
        self.max_rpm = 8333  # 25k / 3åˆ†é’Ÿ
        self.request_window = []  # è¯·æ±‚æ—¶é—´çª—å£
        
        # ç¼“å­˜é…ç½®
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        
        logger.info(f"åˆå§‹åŒ–å®Œæˆ: {len(self.api_keys)}ä¸ªå¯†é’¥, {len(self.models)}ä¸ªæ¨¡å‹")

    async def connect_redis(self):
        """è¿æ¥Redis"""
        try:
            self.redis_client = await redis.from_url(
                self.redis_url,
                encoding="utf-8",
                decode_responses=True
            )
            await self.redis_client.ping()
            logger.info("Redisè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.warning(f"Redisè¿æ¥å¤±è´¥: {e}, ä½¿ç”¨å†…å­˜ç¼“å­˜")
            self.redis_client = None

    def get_cache_key(self, prompt: str, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{model}:{prompt}"
        return f"gemini:cache:{hashlib.md5(content.encode()).hexdigest()}"

    async def get_cached_response(self, prompt: str, model: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„å“åº”"""
        if not self.redis_client:
            return None
        
        try:
            cache_key = self.get_cache_key(prompt, model)
            cached = await self.redis_client.get(cache_key)
            if cached:
                logger.info(f"ç¼“å­˜å‘½ä¸­: {cache_key[:20]}...")
                return cached
        except Exception as e:
            logger.error(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
        
        return None

    async def cache_response(self, prompt: str, model: str, response: str):
        """ç¼“å­˜å“åº”"""
        if not self.redis_client:
            return
        
        try:
            cache_key = self.get_cache_key(prompt, model)
            await self.redis_client.setex(cache_key, self.cache_ttl, response)
            logger.info(f"ç¼“å­˜ä¿å­˜: {cache_key[:20]}...")
        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def check_rate_limit(self) -> bool:
        """æ£€æŸ¥é€Ÿç‡é™åˆ¶"""
        now = time.time()
        # æ¸…ç†1åˆ†é’Ÿå‰çš„è¯·æ±‚è®°å½•
        self.request_window = [t for t in self.request_window if now - t < 60]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.request_window) >= self.max_rpm:
            logger.warning(f"é€Ÿç‡é™åˆ¶: {len(self.request_window)}/{self.max_rpm} rpm")
            return False
        
        self.request_window.append(now)
        return True

    def get_next_key(self) -> Optional[APIKey]:
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„APIå¯†é’¥ï¼ˆè½®è¯¢ç­–ç•¥ï¼‰"""
        attempts = 0
        total_keys = len(self.api_keys)
        
        while attempts < total_keys:
            key = self.api_keys[self.current_key_index]
            self.current_key_index = (self.current_key_index + 1) % total_keys
            
            if key.can_use():
                return key
            
            attempts += 1
        
        # å¦‚æœæ‰€æœ‰å¯†é’¥éƒ½ä¸å¯ç”¨ï¼Œæ‰¾å†·å´æ—¶é—´æœ€çŸ­çš„
        if self.api_keys:
            return min(self.api_keys, key=lambda k: k.last_used if k.is_healthy else float('inf'))
        
        return None

    def get_next_model(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ªæ¨¡å‹ï¼ˆè½®è¯¢ç­–ç•¥ï¼‰"""
        model = self.models[self.current_model_index]
        self.current_model_index = (self.current_model_index + 1) % len(self.models)
        return model

    async def call_gemini_api(
        self,
        prompt: str,
        api_key: APIKey,
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 1000
    ) -> Optional[str]:
        """è°ƒç”¨Gemini API"""
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": api_key.key
        }
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": max_tokens,
                "topP": 0.95,
                "topK": 40
            },
            "safetySettings": [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_NONE"
                }
            ]
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        if 'candidates' in data and data['candidates']:
                            content = data['candidates'][0].get('content', {})
                            parts = content.get('parts', [])
                            if parts:
                                return parts[0].get('text', '')
                    else:
                        error_text = await response.text()
                        logger.error(f"APIé”™è¯¯ {response.status}: {error_text}")
                        
                        # å¤„ç†ç‰¹å®šé”™è¯¯
                        if response.status == 429:  # é€Ÿç‡é™åˆ¶
                            api_key.cooldown = min(api_key.cooldown * 2, 10)
                        elif response.status >= 500:  # æœåŠ¡å™¨é”™è¯¯
                            api_key.error_count += 1
                            if api_key.error_count >= 5:
                                api_key.is_healthy = False
                                logger.warning(f"å¯†é’¥æ ‡è®°ä¸ºä¸å¥åº·: {api_key.key[:10]}...")
        
        except asyncio.TimeoutError:
            logger.error(f"è¯·æ±‚è¶…æ—¶: {model}")
            api_key.error_count += 1
        except Exception as e:
            logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
            api_key.error_count += 1
        
        return None

    async def process_request(
        self,
        prompt: str,
        use_cache: bool = True,
        temperature: float = 0.7,
        max_tokens: int = 1000,
        retry_count: int = 3
    ) -> Dict[str, Any]:
        """å¤„ç†è¯·æ±‚ï¼ˆå¸¦é‡è¯•å’Œé™çº§ï¼‰"""
        start_time = time.time()
        
        # æ£€æŸ¥é€Ÿç‡é™åˆ¶
        if not self.check_rate_limit():
            await asyncio.sleep(1)  # ç­‰å¾…1ç§’
        
        # é€‰æ‹©æ¨¡å‹
        model = self.get_next_model()
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached = await self.get_cached_response(prompt, model)
            if cached:
                self.successful_requests += 1
                return {
                    "success": True,
                    "response": cached,
                    "model": model,
                    "cached": True,
                    "latency": time.time() - start_time
                }
        
        # é‡è¯•é€»è¾‘
        last_error = None
        for attempt in range(retry_count):
            # è·å–å¯ç”¨å¯†é’¥
            api_key = self.get_next_key()
            if not api_key:
                logger.error("æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥")
                await asyncio.sleep(1)
                continue
            
            # ç­‰å¾…å†·å´
            if not api_key.can_use():
                wait_time = api_key.cooldown - (time.time() - api_key.last_used)
                if wait_time > 0:
                    await asyncio.sleep(wait_time)
            
            # è°ƒç”¨API
            logger.info(f"å°è¯• {attempt+1}/{retry_count}: {model} with key {api_key.key[:10]}...")
            response = await self.call_gemini_api(
                prompt, api_key, model, temperature, max_tokens
            )
            
            api_key.use()
            
            if response:
                # æˆåŠŸ
                self.successful_requests += 1
                self.total_requests += 1
                
                # ç¼“å­˜å“åº”
                if use_cache:
                    await self.cache_response(prompt, model, response)
                
                # æ¢å¤å¯†é’¥å¥åº·çŠ¶æ€
                if not api_key.is_healthy and api_key.error_count == 0:
                    api_key.is_healthy = True
                    logger.info(f"å¯†é’¥æ¢å¤å¥åº·: {api_key.key[:10]}...")
                
                return {
                    "success": True,
                    "response": response,
                    "model": model,
                    "cached": False,
                    "attempts": attempt + 1,
                    "latency": time.time() - start_time
                }
            else:
                last_error = f"Model {model} failed"
                # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹
                model = self.get_next_model()
        
        # æ‰€æœ‰å°è¯•å¤±è´¥
        self.failed_requests += 1
        self.total_requests += 1
        
        return {
            "success": False,
            "error": last_error or "All attempts failed",
            "attempts": retry_count,
            "latency": time.time() - start_time
        }

    async def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        healthy_keys = sum(1 for k in self.api_keys if k.is_healthy)
        total_daily = sum(k.daily_count for k in self.api_keys)
        
        return {
            "total_requests": self.total_requests,
            "successful": self.successful_requests,
            "failed": self.failed_requests,
            "success_rate": self.successful_requests / max(1, self.total_requests),
            "healthy_keys": healthy_keys,
            "total_keys": len(self.api_keys),
            "models": self.models,
            "current_rpm": len(self.request_window),
            "max_rpm": self.max_rpm,
            "daily_usage": total_daily,
            "daily_limit": sum(k.daily_limit for k in self.api_keys)
        }

    async def reset_daily_limits(self):
        """é‡ç½®æ¯æ—¥é™åˆ¶ï¼ˆåº”è¯¥æ¯å¤©è°ƒç”¨ä¸€æ¬¡ï¼‰"""
        for key in self.api_keys:
            key.daily_count = 0
            key.error_count = 0
            if key.error_count < 3:
                key.is_healthy = True
        logger.info("æ¯æ—¥é™åˆ¶å·²é‡ç½®")

    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¥åº·çš„å¯†é’¥
        healthy_keys = [k for k in self.api_keys if k.is_healthy]
        if not healthy_keys:
            logger.error("æ²¡æœ‰å¥åº·çš„APIå¯†é’¥ï¼")
            return False
        
        # æ£€æŸ¥Redisè¿æ¥
        if self.redis_client:
            try:
                await self.redis_client.ping()
            except:
                logger.warning("Redisè¿æ¥ä¸¢å¤±ï¼Œå°è¯•é‡è¿...")
                await self.connect_redis()
        
        return True

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """æµ‹è¯•è·¯ç”±å™¨"""
    # åˆå§‹åŒ–è·¯ç”±å™¨
    router = GeminiRouter()
    await router.connect_redis()
    
    # æµ‹è¯•è¯·æ±‚
    test_prompts = [
        "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "è®²ä¸€ä¸ªç¬‘è¯",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "æ¨èä¸€éƒ¨ç”µå½±"
    ]
    
    # å¹¶å‘å¤„ç†è¯·æ±‚
    tasks = []
    for prompt in test_prompts * 5:  # 25ä¸ªè¯·æ±‚
        tasks.append(router.process_request(prompt))
    
    results = await asyncio.gather(*tasks)
    
    # æ‰“å°ç»“æœ
    success_count = sum(1 for r in results if r['success'])
    print(f"\næˆåŠŸç‡: {success_count}/{len(results)}")
    
    # æ‰“å°ç»Ÿè®¡
    stats = await router.get_stats()
    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print(json.dumps(stats, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
