#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾åƒä¸å¤šæ¨¡æ€æ¨¡å‹ å¯ç”¨æ€§ä½“æ£€ï¼ˆæŒ‰Keyé€ä¸€æ¢æµ‹ï¼‰
- è¦†ç›–æˆªå›¾ä¸­â€œç”Ÿæˆæ¨¡å‹/å¤šæ¨¡æ€/Live/TTSâ€ç­‰æ¨¡å‹
- å¯¹æ¯ä¸ªæ¨¡å‹å’Œæ¯ä¸ªKey:
  1) GET /models/{model} å…ƒæ•°æ®æ¢æµ‹ï¼ˆå­˜åœ¨æ€§ï¼‰
  2) ä¾æ¬¡å°è¯•ä»¥ä¸‹ç«¯ç‚¹ï¼ˆå®¹é”™ï¼Œä¸»è¦ä¸ºäº†åˆ¤æ–­â€œå¯è¾¾/å—é™/éœ€ä¸“ç”¨ç«¯ç‚¹â€ï¼‰ï¼š
     - :generateContent (ç®€å•æ–‡æœ¬prompt)
     - :generateImages å’Œ :generateImage ï¼ˆå›¾åƒç”ŸæˆçŒœæµ‹ç«¯ç‚¹ï¼‰
     - :generateSpeech å’Œ :generateAudio ï¼ˆTTSçŒœæµ‹ç«¯ç‚¹ï¼‰
  - å°†HTTPçŠ¶æ€ä¸é”™è¯¯çŸ­è¯­çº³å…¥ç»“æœï¼ˆ200/400/403/404/429 ç­‰ï¼‰ï¼Œæ®æ­¤åˆ¤â€œå¯ç”¨/å­˜åœ¨ä½†éœ€ä¸“ç”¨ç«¯ç‚¹/ä¸å¯ç”¨/é™é€Ÿâ€ã€‚
- è¾“å‡ºï¼š.reports/media_audit_<timestamp>.json / .md
"""

import os
import re
import json
import time
import urllib.request
import urllib.error
from datetime import datetime

ROOT = "/mnt/volume_sgp1_01/svs_bot"
ENV_BAK = os.path.join(ROOT, ".env.bak")
REPORT_DIR = os.path.join(ROOT, ".reports")
API_BASE = "https://generativelanguage.googleapis.com/v1"

# ç›®æ ‡æ¨¡å‹ï¼ˆè¦†ç›–æˆªå›¾ä¸­å‡ºç°çš„ç±»åˆ«ï¼Œå­˜åœ¨ä¸å¦ä»¥Probeä¸ºå‡†ï¼‰
TARGET_MODELS = [
    # ç”Ÿæˆ/å¤šæ¨¡æ€
    "gemini-2.0-flash-preview-image-generation",
    "gemini-2.5-flash-preview-image",
    "gemini-2.5-flash-tts",
    "gemini-2.5-pro-tts",
    "imagen-3.0-generate",
    "imagen-4.0-fast-generate",
    "imagen-4.0-generate",
    "imagen-4.0-ultra-generate",
    "veo-2.0-generate-001",
    "veo-3.0-fast-generate",
    "veo-3.0-generate",
    # Live
    "gemini-2.0-flash-live",
    "gemini-2.5-flash-live",
    "gemini-2.5-flash-native-audio-dialog",
]

# å¤‡é€‰ç«¯ç‚¹ä¸ç¤ºä¾‹payloadï¼ˆå°½åŠ›åŒ¹é…ï¼Œå…è®¸400ï¼‰
ENDPOINTS = [
    ("generateContent", {"contents": [{"parts": [{"text": "Ping"}]}]}),
    ("generateImages", {"prompt": {"text": "A cute cat, photorealistic"}}),
    ("generateImage", {"prompt": "A cute cat, photorealistic"}),
    ("generateSpeech", {"input": {"text": "Hello from audit"}, "audioConfig": {"audioEncoding": "MP3"}}),
    ("generateAudio", {"text": "Hello from audit"}),
]

HEADERS = {"Content-Type": "application/json"}


def load_keys_from_env(env_path: str):
    if not os.path.exists(env_path):
        return []
    keys = []
    pat = re.compile(r"^\s*(GEMINI_GROUP_[A-D]_KEY_\d+)\s*=\s*\"?([^\"\n]+)\"?\s*$")
    with open(env_path, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            m = pat.match(line)
            if m:
                value = m.group(2).strip()
                if value and len(value) > 20:
                    keys.append(value)
    # å»é‡
    seen, ordered = set(), []
    for k in keys:
        if k not in seen:
            seen.add(k)
            ordered.append(k)
    return ordered


def http_get(url: str, timeout=10):
    try:
        with urllib.request.urlopen(urllib.request.Request(url), timeout=timeout) as r:
            return 200, r.read().decode("utf-8", errors="ignore")
    except urllib.error.HTTPError as e:
        try:
            body = e.read().decode("utf-8", errors="ignore")
        except Exception:
            body = ""
        return e.code, body
    except Exception as e:
        return -1, str(e)


def http_post(url: str, payload: dict, timeout=15):
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=HEADERS)
    start = time.time()
    try:
        with urllib.request.urlopen(req, timeout=timeout) as r:
            body = r.read().decode("utf-8", errors="ignore")
            latency = time.time() - start
            return 200, body, latency
    except urllib.error.HTTPError as e:
        try:
            body = e.read().decode("utf-8", errors="ignore")
        except Exception:
            body = ""
        latency = time.time() - start
        return e.code, body, latency
    except Exception as e:
        latency = time.time() - start
        return -1, str(e), latency


def probe_model_for_key(key: str, model: str):
    result = {
        "metadata": None,
        "endpoints": [],
    }

    # 1) å…ƒæ•°æ®
    meta_url = f"{API_BASE}/models/{model}?key={key}"
    code, body = http_get(meta_url)
    result["metadata"] = {"code": code, "snippet": (body or "")[:160]}

    # 2) å„ç«¯ç‚¹å°è¯•
    for ep, payload in ENDPOINTS:
        url = f"{API_BASE}/models/{model}:{ep}?key={key}"
        code, body, latency = http_post(url, payload)
        snippet = (body or "")[:160]
        result["endpoints"].append({
            "endpoint": ep,
            "code": code,
            "latency": round(latency, 3),
            "snippet": snippet,
        })
        # é™é€Ÿ
        time.sleep(0.2)

    return result


def summarize(results):
    summary = {"generated_at": datetime.utcnow().isoformat() + "Z", "models": {}}
    for model, per_key in results.items():
        total = len(per_key)
        meta_200 = 0
        any_200 = 0
        any_403 = 0
        any_404 = 0
        any_429 = 0
        for r in per_key.values():
            # metadata
            try:
                if int(r.get("metadata", {}).get("code", 0)) == 200:
                    meta_200 += 1
            except Exception:
                pass
            # endpoints list of dicts
            codes = []
            for ep in r.get("endpoints", []):
                try:
                    codes.append(int(ep.get("code", 0)))
                except Exception:
                    continue
            if any(c == 200 for c in codes):
                any_200 += 1
            if any(c == 403 for c in codes):
                any_403 += 1
            if any(c == 404 for c in codes):
                any_404 += 1
            if any(c == 429 for c in codes):
                any_429 += 1
        summary["models"][model] = {
            "keys": total,
            "metadata_200": meta_200,
            "any_200": any_200,
            "any_403": any_403,
            "any_404": any_404,
            "any_429": any_429,
        }
    return summary


def to_markdown(summary: dict) -> str:
    lines = []
    lines.append("# å›¾åƒ/å¤šæ¨¡æ€æ¨¡å‹ä½“æ£€æ‘˜è¦\n")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {summary['generated_at']}\n")
    lines.append("## æ¨¡å‹æ±‡æ€»\n")
    for model, s in summary["models"].items():
        lines.append(f"- **{model}**: å…ƒæ•°æ®200={s['metadata_200']}/{s['keys']} | ä»»ä¸€ç«¯ç‚¹200={s['any_200']} | 403={s['any_403']} | 404={s['any_404']} | 429={s['any_429']}")
    return "\n".join(lines) + "\n"


def main():
    os.makedirs(REPORT_DIR, exist_ok=True)
    keys = load_keys_from_env(ENV_BAK)
    if not keys:
        print("âŒ æœªå‘ç°ä»»ä½•Key (.env.bak)")
        return

    print(f"ğŸ” å›¾åƒ/å¤šæ¨¡æ€ä½“æ£€ï¼š{len(keys)} keys Ã— {len(TARGET_MODELS)} models")
    results = {m: {} for m in TARGET_MODELS}

    # é™é€Ÿæ§åˆ¶ï¼šæ¯æ¨¡å‹Ã—æ¯Key å°è¯•å¤šç«¯ç‚¹ï¼Œæ³¨æ„èŠ‚æµ
    for mi, model in enumerate(TARGET_MODELS, 1):
        print(f"\n== æ¨¡å‹ {mi}/{len(TARGET_MODELS)}: {model}")
        for ki, key in enumerate(keys, 1):
            print(f"  - Key {ki}/{len(keys)} {key[:20]}...")
            r = probe_model_for_key(key, model)
            results[model][f"key_{ki}"] = {
                "key_short": key[:15] + "...",
                "metadata": r["metadata"],
                "endpoints": r["endpoints"],
            }
            # æ¯5ä¸ªKeyç¨ä½œç­‰å¾…
            if ki % 5 == 0:
                time.sleep(2.0)
        # æ¨¡å‹ä¹‹é—´å†·å´
        time.sleep(1.0)

    summary = summarize(results)
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    json_path = os.path.join(REPORT_DIR, f"media_audit_{ts}.json")
    md_path = os.path.join(REPORT_DIR, f"media_audit_{ts}.md")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({"summary": summary, "results": results}, f, indent=2, ensure_ascii=False)
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(to_markdown(summary))

    print("\nâœ… å®Œæˆï¼š")
    print("  ", json_path)
    print("  ", md_path)


if __name__ == "__main__":
    main()
