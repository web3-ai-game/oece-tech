#!/usr/bin/env python3
"""
æ¨¡å‹è·¯ç”±å™¨ - æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ¨¡å‹å’ŒAPI Key
"""

import logging
from datetime import datetime, timedelta
from typing import Tuple, Optional
from collections import defaultdict
import asyncio

import google.generativeai as genai

from config import Config, ModelType, TaskType, APIKeyConfig

logger = logging.getLogger(__name__)


class UsageTracker:
    """ä½¿ç”¨é‡è¿½è¸ªå™¨"""
    
    def __init__(self):
        # {(model, key, date): count}
        self.daily_usage = defaultdict(int)
        # {(model, key, minute): count}
        self.minute_usage = defaultdict(int)
        self.last_cleanup = datetime.now()
    
    def record(self, model: ModelType, key_name: str):
        """è®°å½•ä¸€æ¬¡ä½¿ç”¨"""
        today = datetime.now().date()
        current_minute = datetime.now().replace(second=0, microsecond=0)
        
        self.daily_usage[(model, key_name, today)] += 1
        self.minute_usage[(model, key_name, current_minute)] += 1
        
        # å®šæœŸæ¸…ç†æ—§æ•°æ®
        self._cleanup()
    
    def get_daily_count(self, model: ModelType, key_name: str) -> int:
        """è·å–ä»Šæ—¥ä½¿ç”¨æ¬¡æ•°"""
        today = datetime.now().date()
        return self.daily_usage.get((model, key_name, today), 0)
    
    def get_minute_count(self, model: ModelType, key_name: str) -> int:
        """è·å–å½“å‰åˆ†é’Ÿä½¿ç”¨æ¬¡æ•°"""
        current_minute = datetime.now().replace(second=0, microsecond=0)
        return self.minute_usage.get((model, key_name, current_minute), 0)
    
    def _cleanup(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        now = datetime.now()
        if (now - self.last_cleanup).seconds < 3600:  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
            return
        
        # æ¸…ç†åˆ†é’Ÿçº§æ•°æ®ï¼ˆä¿ç•™æœ€è¿‘2åˆ†é’Ÿï¼‰
        cutoff_minute = now - timedelta(minutes=2)
        keys_to_delete = [
            k for k in self.minute_usage.keys()
            if k[2] < cutoff_minute
        ]
        for k in keys_to_delete:
            del self.minute_usage[k]
        
        self.last_cleanup = now


class ModelRouter:
    """æ¨¡å‹è·¯ç”±å™¨ - æ™ºèƒ½é€‰æ‹©æ¨¡å‹å’ŒKey"""
    
    def __init__(self):
        self.usage_tracker = UsageTracker()
        self.api_keys = Config.API_KEYS
        logger.info("ğŸ¯ ModelRouter initialized")
    
    async def route(
        self, 
        task_type: TaskType,
        prefer_backup: bool = False,
        is_owner: bool = False
    ) -> Tuple[ModelType, APIKeyConfig, genai.GenerativeModel]:
        """
        è·¯ç”±åˆ°æœ€ä¼˜æ¨¡å‹å’ŒKey
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            prefer_backup: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å¤‡ç”¨Key
            is_owner: æ˜¯å¦æ˜¯æ‰€æœ‰è€… (@svskilo)
            
        Returns:
            (æ¨¡å‹ç±»å‹, API Keyé…ç½®, Geminiæ¨¡å‹å®ä¾‹)
        """
        
        # 1. æ ¹æ®ä»»åŠ¡ç±»å‹å’Œç”¨æˆ·èº«ä»½é€‰æ‹©æ¨¡å‹
        if is_owner:
            # Owner: ä½¿ç”¨ä¸»Keyï¼Œæ‰€æœ‰æ¨¡å‹å¯ç”¨
            model_type = Config.TASK_ROUTING.get(task_type, ModelType.FLASH_LITE)
            prefer_backup = False
        else:
            # å…¶ä»–ç”¨æˆ·: ç»Ÿä¸€ä½¿ç”¨å¤‡ç”¨Keyçš„Flash-Lite
            if Config.OTHERS_USE_BACKUP_LITE:
                model_type = ModelType.FLASH_LITE
                prefer_backup = True
            else:
                model_type = Config.TASK_ROUTING.get(task_type, ModelType.FLASH_LITE)
        
        model_config = Config.MODELS[model_type]
        
        # 2. é€‰æ‹© API Key
        api_key = self._select_api_key(model_type, prefer_backup, force_backup=prefer_backup and not is_owner)
        
        # 3. æ£€æŸ¥é€Ÿç‡é™åˆ¶
        if not self._check_rate_limit(model_type, api_key.name):
            # é™çº§ç­–ç•¥
            logger.warning(f"âš ï¸  {model_type.value} rate limit reached, fallback...")
            return await self._fallback_strategy(task_type)
        
        # 4. åˆ›å»ºæ¨¡å‹å®ä¾‹
        genai.configure(api_key=api_key.key)
        model = genai.GenerativeModel(model_config.name)
        
        # 5. è®°å½•ä½¿ç”¨
        self.usage_tracker.record(model_type, api_key.name)
        
        logger.info(
            f"âœ… Routed {task_type.value} -> {model_type.value} "
            f"(Key: {api_key.name}, "
            f"Daily: {self.usage_tracker.get_daily_count(model_type, api_key.name)}/{model_config.daily_limit})"
        )
        
        return model_type, api_key, model
    
    def _select_api_key(self, model_type: ModelType, prefer_backup: bool = False, force_backup: bool = False) -> APIKeyConfig:
        """é€‰æ‹© API Key"""
        
        # å¼ºåˆ¶ä½¿ç”¨å¤‡ç”¨Keyï¼ˆå…¶ä»–ç”¨æˆ·ï¼‰
        if force_backup:
            backup_keys = [k for k in self.api_keys if not k.is_primary]
            if backup_keys:
                return backup_keys[0]
        
        # ç¾¤èŠä¼˜å…ˆä½¿ç”¨å¤‡ç”¨Key
        if prefer_backup:
            backup_keys = [k for k in self.api_keys if not k.is_primary]
            if backup_keys:
                return backup_keys[0]
        
        # æ£€æŸ¥ä¸»Keyé…é¢
        primary_key = next(k for k in self.api_keys if k.is_primary)
        model_config = Config.MODELS[model_type]
        
        daily_count = self.usage_tracker.get_daily_count(model_type, primary_key.name)
        
        # å¦‚æœä¸»Keyæ¥è¿‘é™é¢ï¼ˆ80%ï¼‰ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨
        if daily_count >= model_config.daily_limit * Config.RATE_LIMIT_BUFFER:
            logger.warning(f"âš ï¸  Primary key near limit ({daily_count}/{model_config.daily_limit}), switching to backup")
            backup_keys = [k for k in self.api_keys if not k.is_primary]
            if backup_keys:
                return backup_keys[0]
        
        return primary_key
    
    def _check_rate_limit(self, model_type: ModelType, key_name: str) -> bool:
        """æ£€æŸ¥é€Ÿç‡é™åˆ¶"""
        model_config = Config.MODELS[model_type]
        
        # æ£€æŸ¥æ—¥é™é¢
        daily_count = self.usage_tracker.get_daily_count(model_type, key_name)
        if daily_count >= model_config.daily_limit:
            logger.warning(f"âŒ Daily limit reached: {daily_count}/{model_config.daily_limit}")
            return False
        
        # æ£€æŸ¥åˆ†é’Ÿé™é¢ï¼ˆä»…Proï¼‰
        if model_config.minute_limit:
            minute_count = self.usage_tracker.get_minute_count(model_type, key_name)
            if minute_count >= model_config.minute_limit:
                logger.warning(f"âŒ Minute limit reached: {minute_count}/{model_config.minute_limit}")
                return False
        
        return True
    
    async def _fallback_strategy(
        self, 
        task_type: TaskType
    ) -> Tuple[ModelType, APIKeyConfig, genai.GenerativeModel]:
        """é™çº§ç­–ç•¥"""
        
        # å¤æ‚ä»»åŠ¡ Pro -> Flash -> Flash-Lite
        if task_type == TaskType.TASK_COMPLEX:
            # å°è¯• Flash
            logger.info("ğŸ”„ Fallback: Pro -> Flash")
            flash_key = self._select_api_key(ModelType.FLASH, prefer_backup=True)
            if self._check_rate_limit(ModelType.FLASH, flash_key.name):
                genai.configure(api_key=flash_key.key)
                model = genai.GenerativeModel(Config.MODELS[ModelType.FLASH].name)
                self.usage_tracker.record(ModelType.FLASH, flash_key.name)
                return ModelType.FLASH, flash_key, model
            
            # æœ€åé™çº§åˆ° Flash-Lite
            logger.info("ğŸ”„ Fallback: Flash -> Flash-Lite")
            lite_key = self._select_api_key(ModelType.FLASH_LITE)
            genai.configure(api_key=lite_key.key)
            model = genai.GenerativeModel(Config.MODELS[ModelType.FLASH_LITE].name)
            self.usage_tracker.record(ModelType.FLASH_LITE, lite_key.name)
            return ModelType.FLASH_LITE, lite_key, model
        
        # ç®€å•ä»»åŠ¡ Flash -> Flash-Lite
        elif task_type == TaskType.TASK_SIMPLE:
            logger.info("ğŸ”„ Fallback: Flash -> Flash-Lite")
            lite_key = self._select_api_key(ModelType.FLASH_LITE, prefer_backup=True)
            genai.configure(api_key=lite_key.key)
            model = genai.GenerativeModel(Config.MODELS[ModelType.FLASH_LITE].name)
            self.usage_tracker.record(ModelType.FLASH_LITE, lite_key.name)
            return ModelType.FLASH_LITE, lite_key, model
        
        # é»˜è®¤ä½¿ç”¨ Flash-Lite
        lite_key = self._select_api_key(ModelType.FLASH_LITE)
        genai.configure(api_key=lite_key.key)
        model = genai.GenerativeModel(Config.MODELS[ModelType.FLASH_LITE].name)
        self.usage_tracker.record(ModelType.FLASH_LITE, lite_key.name)
        return ModelType.FLASH_LITE, lite_key, model
    
    async def wait_for_rate_limit(self, model_type: ModelType):
        """ç­‰å¾…é€Ÿç‡é™åˆ¶å†·å´"""
        logger.info(f"â³ Waiting {Config.COOLDOWN_SECONDS}s for rate limit cooldown...")
        await asyncio.sleep(Config.COOLDOWN_SECONDS)
