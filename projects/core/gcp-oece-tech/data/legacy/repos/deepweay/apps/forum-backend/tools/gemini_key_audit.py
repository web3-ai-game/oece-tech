#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini å…¨KeyÃ—å¤šæ¨¡å‹ ä½“æ£€è„šæœ¬
- é€ä¸ªKeyæµ‹è¯•æŒ‡å®šæ¨¡å‹å¯ç”¨æ€§ä¸å»¶è¿Ÿ
- å¯é€‰çŸ­çªå‘ä»¥ç²—æµ‹RPMé˜ˆå€¼ï¼ˆé¿å…è¿‡è½½ï¼Œé»˜è®¤5æ¬¡/Key/æ¨¡å‹ï¼‰
- ç»“æœå†™å…¥ï¼š
  * JSON: .reports/gemini_audit_<timestamp>.json
  * Markdown: .reports/gemini_audit_<timestamp>.md
  * Redisï¼ˆå¯é€‰ï¼‰: audit:{date}:<keyprefix>:<model>

ç”¨æ³•ç¤ºä¾‹ï¼š
  python3 tools/gemini_key_audit.py \
    --models gemini-2.0-flash-lite gemini-2.0-flash gemini-2.5-flash-lite gemini-2.5-flash gemini-2.5-pro \
    --burst 5 --delay 0.15
"""

import os
import re
import sys
import json
import time
import math
import argparse
import urllib.request
import urllib.error
from datetime import datetime

try:
    import redis  # å¯é€‰
except Exception:
    redis = None

ROOT = "/mnt/volume_sgp1_01/svs_bot"
ENV_BAK = os.path.join(ROOT, ".env.bak")
REPORT_DIR = os.path.join(ROOT, ".reports")

DEFAULT_MODELS = [
    "gemini-2.0-flash-lite",
    "gemini-2.0-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.5-flash",
    "gemini-2.5-pro",
]

HEADERS = {"Content-Type": "application/json"}
API_FMT = "https://generativelanguage.googleapis.com/v1/models/{model}:generateContent?key={key}"


def load_keys_from_env(env_path: str):
    """ä» .env.bak è¯»å–æ‰€æœ‰ GEMINI_GROUP_* Key"""
    if not os.path.exists(env_path):
        print(f"âŒ æœªæ‰¾åˆ° {env_path}")
        return []
    keys = []
    pat = re.compile(r"^\s*(GEMINI_GROUP_[A-D]_KEY_\d+)\s*=\s*\"?([^\"\n]+)\"?\s*$")
    with open(env_path, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            m = pat.match(line)
            if m:
                value = m.group(2).strip()
                if value and len(value) > 20:
                    keys.append(value)
    # å»é‡ä¿æŒé¡ºåº
    seen = set()
    ordered = []
    for k in keys:
        if k not in seen:
            seen.add(k)
            ordered.append(k)
    return ordered


def call_model(key: str, model: str, text: str = "Hi", timeout_s: float = 12.0):
    """å¯¹æŒ‡å®šæ¨¡å‹åšä¸€æ¬¡ç®€å•è°ƒç”¨ï¼Œè¿”å› (ok, latency, code, tokens, err)"""
    url = API_FMT.format(model=model, key=key)
    payload = {"contents": [{"parts": [{"text": text}]}]}
    data = json.dumps(payload).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=HEADERS)

    start = time.time()
    try:
        with urllib.request.urlopen(req, timeout=timeout_s) as resp:
            raw = resp.read().decode("utf-8", errors="ignore")
            latency = time.time() - start
            try:
                obj = json.loads(raw)
            except Exception:
                obj = {}
            tokens = 0
            if isinstance(obj, dict):
                usage = obj.get("usageMetadata") or {}
                tokens = usage.get("totalTokenCount", 0)
                ok = bool(obj.get("candidates"))
            else:
                ok = False
            return ok, latency, 200, tokens, None
    except urllib.error.HTTPError as e:
        latency = time.time() - start
        detail = None
        try:
            detail = e.read().decode("utf-8", errors="ignore")
        except Exception:
            detail = None
        return False, latency, e.code, 0, detail
    except Exception as e:
        latency = time.time() - start
        return False, latency, -1, 0, str(e)


def burst_probe(key: str, model: str, n: int = 5, delay: float = 0.15):
    """çŸ­çªå‘æ¢æµ‹ï¼šè¿ç»­ n æ¬¡å¿«é€Ÿè°ƒç”¨ï¼Œè¿”å›æˆåŠŸæ¬¡æ•°ä¸æ˜¯å¦è§¦å‘429"""
    success = 0
    got_429 = False
    latencies = []
    for i in range(n):
        ok, lat, code, tokens, err = call_model(key, model)
        latencies.append(lat)
        if ok:
            success += 1
        if code == 429:
            got_429 = True
        time.sleep(max(0.0, delay))
    return {
        "attempts": n,
        "success": success,
        "avg_latency": round(sum(latencies) / len(latencies), 3) if latencies else 0.0,
        "got_429": got_429,
    }


def connect_redis():
    if not redis:
        return None
    try:
        r = redis.Redis(host="localhost", port=6379, db=0, decode_responses=True)
        r.ping()
        return r
    except Exception:
        return None


def write_redis(r, date_prefix: str, key: str, model: str, record: dict):
    if not r:
        return
    kp = f"audit:{date_prefix}:{key[:15]}:{model}"
    try:
        r.hset(kp, mapping={k: json.dumps(v) if isinstance(v, (dict, list)) else v for k, v in record.items()})
        r.expire(kp, 86400 * 7)
    except Exception:
        pass


def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)


def to_markdown(summary: dict) -> str:
    lines = []
    lines.append("# Gemini å…¨KeyÃ—å¤šæ¨¡å‹ä½“æ£€æŠ¥å‘Š")
    lines.append("")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {summary['generated_at']}")
    lines.append("")

    # æ¨¡å‹æ€»ä½“
    lines.append("## æ¨¡å‹å¯ç”¨æ€§æ€»è§ˆ")
    for m in summary["models_stats"]:
        s = summary["models_stats"][m]
        lines.append(f"- **{m}**: å¯ç”¨Keys {s['available_keys']}/{s['total_keys']} (å¯ç”¨ç‡ {s['availability_rate']}) | å¹³å‡å»¶è¿Ÿ {s['avg_latency']}s | 429è§¦å‘ç‡ {s['rate_limit_rate']}")
    lines.append("")

    # Key å¥åº·
    lines.append("## Keyå¥åº·åº¦æ’å (å‰10)")
    ranked = sorted(summary["keys"].items(), key=lambda kv: kv[1]["health_score"], reverse=True)
    for i, (k, info) in enumerate(ranked[:10], 1):
        lines.append(f"{i}. {info['key_short']}: å¥åº·åº¦ {info['health_score']:.2f} (é€šè¿‡ {info['passed_tests']}/{info['total_tests']})")
    lines.append("")

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="Gemini å…¨KeyÃ—å¤šæ¨¡å‹ ä½“æ£€è„šæœ¬")
    parser.add_argument("--models", nargs="*", default=DEFAULT_MODELS, help="å¾…æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨")
    parser.add_argument("--burst", type=int, default=5, help="æ¯Keyæ¯æ¨¡å‹çªå‘è¯·æ±‚æ¬¡æ•°(ç”¨äºç²—æµ‹RPM)")
    parser.add_argument("--delay", type=float, default=0.15, help="çªå‘è¯·æ±‚é—´éš”ç§’")
    parser.add_argument("--keys", nargs="*", default=None, help="ç›´æ¥æä¾›Keys(å¯é€‰)ï¼Œå¦åˆ™ä».env.bakè¯»å–")
    args = parser.parse_args()

    ensure_dir(REPORT_DIR)

    keys = args.keys if args.keys else load_keys_from_env(ENV_BAK)
    if not keys:
        print("âŒ æœªå‘ç°ä»»ä½•Gemini Keysï¼Œè¯·æ£€æŸ¥ .env.bak æˆ–ä¼ å…¥ --keys")
        sys.exit(1)

    test_models = args.models
    date_prefix = datetime.utcnow().strftime("%Y-%m-%d")

    r = connect_redis()
    if r:
        print("âœ… Rediså·²è¿æ¥ï¼Œç»“æœå°†å†™å…¥Redis")
    else:
        print("âš ï¸ Redisæœªè¿æ¥ï¼Œè·³è¿‡Rediså†™å…¥")

    print(f"ğŸ” å¼€å§‹ä½“æ£€ï¼š{len(keys)} ä¸ªKeys Ã— {len(test_models)} ä¸ªæ¨¡å‹")

    results = {
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "keys": {},
        "models_stats": {},
    }

    # ä¸»å¾ªç¯
    for idx, key in enumerate(keys, 1):
        print(f"\nã€Key {idx}/{len(keys)}ã€‘{key[:20]}...")
        key_info = {
            "key_short": key[:15] + "...",
            "models": {},
            "healthy": True,
            "total_tests": 0,
            "passed_tests": 0,
        }

        for model in test_models:
            # å…ˆå•æ¬¡åŠŸèƒ½æµ‹è¯•
            ok, latency, code, tokens, err = call_model(key, model)
            record = {
                "single_ok": ok,
                "single_latency": round(latency, 3),
                "code": code,
                "tokens": tokens,
            }

            # çŸ­çªå‘RPMç²—æµ‹
            burst = burst_probe(key, model, n=args.burst, delay=args.delay)
            record.update({
                "burst_attempts": burst["attempts"],
                "burst_success": burst["success"],
                "burst_avg_latency": burst["avg_latency"],
                "burst_got_429": burst["got_429"],
            })

            key_info["total_tests"] += 1
            if ok:
                key_info["passed_tests"] += 1
            if code in (403, 429) or burst["got_429"]:
                key_info["healthy"] = False

            key_info["models"][model] = record
            write_redis(r, date_prefix, key, model, record)

            print(
                f"  {model}: {'âœ…' if ok else 'âŒ'} | å•æ¬¡ {record['single_latency']}s | "
                f"çªå‘ {record['burst_success']}/{record['burst_attempts']} | 429={record['burst_got_429']}"
            )
            time.sleep(0.2)

        key_info["health_score"] = (
            key_info["passed_tests"] / key_info["total_tests"] if key_info["total_tests"] else 0.0
        )
        results["keys"][f"key_{idx}"] = key_info

        if idx % 5 == 0:
            print("  â¸ï¸ æ‰¹æ¬¡ä¼‘æ¯ 2s ä»¥é¿å…é™é€Ÿ...")
            time.sleep(2.0)

    # æ¨¡å‹èšåˆ
    for model in test_models:
        available = 0
        total = len(keys)
        total_latency = 0.0
        rate429 = 0
        for key_info in results["keys"].values():
            rec = key_info["models"].get(model)
            if not rec:
                continue
            if rec.get("single_ok"):
                available += 1
                total_latency += rec.get("single_latency", 0.0)
            if rec.get("burst_got_429"):
                rate429 += 1
        avg_latency = round(total_latency / available, 3) if available else 0.0
        results["models_stats"][model] = {
            "available_keys": available,
            "total_keys": total,
            "availability_rate": f"{(available/total*100):.0f}%",
            "avg_latency": avg_latency,
            "rate_limit_rate": f"{(rate429/total*100):.0f}%",
        }

    # å†™æŠ¥å‘Š
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    ensure_dir(REPORT_DIR)
    json_path = os.path.join(REPORT_DIR, f"gemini_audit_{ts}.json")
    md_path = os.path.join(REPORT_DIR, f"gemini_audit_{ts}.md")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(to_markdown(results))

    print("\nâœ… ä½“æ£€å®Œæˆï¼š")
    print(f"  JSON: {json_path}")
    print(f"  Markdown: {md_path}")
    if r:
        print("  Redis: å·²å†™å…¥ï¼ˆä¿å­˜7å¤©ï¼‰")


if __name__ == "__main__":
    main()
