#!/usr/bin/env python3
# å°çˆ±åŒå­¦ - æ™ºèƒ½è·¯ç”±ç‰ˆæœ¬
# é›†æˆ: 5è½®è®°å¿† + å…³é”®è¯è§¦å‘ + æ™ºèƒ½Keyè·¯ç”±

import os
import json
import time
import random
import re
import urllib.request
import urllib.parse
from datetime import datetime
from collections import defaultdict
from gemini_key_router_v2 import GeminiKeyRouter, create_router_from_env
try:
    from supabase import create_client as _create_sb
except Exception:
    _create_sb = None

# Telegramé…ç½®
TOKEN = '8242036113:AAGhqTo7_Lb5tMHT2WlspWV-RoxrWdki3Wg'
OWNER_ID = 6136230855
API = f'https://api.telegram.org/bot{TOKEN}/'

# åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±å™¨
print("ğŸ”§ åˆå§‹åŒ–æ™ºèƒ½Keyè·¯ç”±å™¨...")
key_router = create_router_from_env()

# ç”¨æˆ·ç­‰çº§é…ç½®ä¸æ¨¡å¼
# ç­‰çº§: member(1), pro(2), pro_annual(3), admin
USER_TIERS = {
    OWNER_ID: 'admin',  # ç®¡ç†å‘˜
    # å…¶ä»–ç”¨æˆ·: user_id: 'member' | 'pro' | 'pro_annual'
}

# DM ä¸ç¾¤èŠé»˜è®¤æ¨¡å‹
DEFAULT_DM_MODEL = 'gemini-2.5-flash'
DEFAULT_GROUP_MODEL = 'gemini-2.5-flash-lite'

# äººæ ¼å
AGENT_NAME = 'svs-R01'

# ç®¡ç†å‘˜â€œå·¥ä½œæ¨¡å¼â€
ADMIN_DM_MODE = {}          # user_id -> 'work' | 'crush'
ADMIN_THROTTLE_S = 1.5
ADMIN_LAST_DM = {}          # user_id -> timestamp

# Supabase ç”¨æˆ·å±‚çº§åˆ·æ–°ï¼ˆæ¯12å°æ—¶ä¸€æ¬¡ï¼Œå¯é€‰ï¼‰
SB_URL = os.getenv('SUPABASE_URL')
SB_KEY = os.getenv('SUPABASE_ANON_KEY') or os.getenv('SUPABASE_SERVICE_KEY')
_SB = _create_sb(SB_URL, SB_KEY) if (_create_sb and SB_URL and SB_KEY) else None
_LAST_USER_SYNC = 0

def refresh_user_tiers(force=False):
    global USER_TIERS, _LAST_USER_SYNC
    if not _SB:
        return False
    now = time.time()
    if not force and now - _LAST_USER_SYNC < 12 * 3600:
        return False
    try:
        data = _SB.table('users').select('uid,tier,is_admin').execute()
        rows = data.data or []
        for r in rows:
            uid = int(r.get('uid'))
            tier = (r.get('tier') or 'member').lower()
            if r.get('is_admin'):
                USER_TIERS[uid] = 'admin'
            else:
                USER_TIERS[uid] = tier if tier in ('member','pro','pro_annual','admin','root') else 'member'
        _LAST_USER_SYNC = now
        return True
    except Exception:
        return False

# è®°å¿†ç³»ç»Ÿ
# ç§èŠ: æŒä¹…åŒ–åˆ°æ–‡ä»¶; ç¾¤èŠ: ä¼šè¯ä¸´æ—¶è®°å¿†(æ¯ç”¨æˆ·5æ¬¡)
user_memories = defaultdict(list)  # å…¼å®¹æ—§é€»è¾‘(å°†ä¸å†ç”¨äºç§èŠæŒä¹…åŒ–)
DM_MEMORY_DIR = os.path.join(os.path.dirname(__file__), 'private_memory')
os.makedirs(DM_MEMORY_DIR, exist_ok=True)

# äº‹ä»¶æ—¥å¿—ï¼ˆJSONLï¼Œæœ¬åœ°è½»é‡å½’æ¡£ï¼Œä¾›Workeræ‰¹å¤„ç†åˆ°Postgresï¼‰
LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, 'events.jsonl')

def append_event(event):
    try:
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event, ensure_ascii=False) + '\n')
    except Exception:
        pass

# ç¾¤èŠå¹¶å‘ä¼šè¯: æ¯ç¾¤æœ€å¤š5ä¸ªå¹¶å‘ç”¨æˆ·, æ¯ç”¨æˆ·5æ¬¡å›å¤
group_sessions = defaultdict(dict)  # {chat_id: {user_id: {messages:[], replies:int, started_at:str}}}
MAX_GROUP_TURNS = 5
MAX_GROUP_CONCURRENT = 5

# å…³é”®è¯è§¦å‘
KEYWORD_TRIGGERS = {
    'çˆ±ä½ ': {'emotion': 'love', 'importance': 10},
    'å–œæ¬¢ä½ ': {'emotion': 'like', 'importance': 8},
    'æƒ³ä½ ': {'emotion': 'miss', 'importance': 7},
    'æ°¸è¿œ': {'emotion': 'promise', 'importance': 9},
    'åœ¨ä¸€èµ·': {'emotion': 'together', 'importance': 9},
    'æ‰¿è¯º': {'emotion': 'promise', 'importance': 8},
    'çº¦å®š': {'emotion': 'promise', 'importance': 7},
    'å¸®æˆ‘': {'emotion': 'help', 'importance': 5},
    'ä»€ä¹ˆæ˜¯': {'emotion': 'question', 'importance': 4},
    'æ€ä¹ˆ': {'emotion': 'question', 'importance': 4},
    'ä¸ºä»€ä¹ˆ': {'emotion': 'question', 'importance': 4},
}

def get_user_tier(user_id):
    """è·å–ç”¨æˆ·ç­‰çº§"""
    # å°è¯•å‘¨æœŸæ€§åˆ·æ–°ç”¨æˆ·å±‚çº§
    refresh_user_tiers(False)
    return USER_TIERS.get(user_id, 'member')

def add_to_memory(user_id, user_msg, ai_response):
    """æ·»åŠ åˆ°è®°å¿†"""
    if user_id not in user_memories:
        user_memories[user_id] = []
    
    user_memories[user_id].append({
        'role': 'user',
        'content': user_msg,
        'time': datetime.now().isoformat()
    })
    user_memories[user_id].append({
        'role': 'assistant',
        'content': ai_response,
        'time': datetime.now().isoformat()
    })
    
    if len(user_memories[user_id]) > 10:
        user_memories[user_id] = user_memories[user_id][-10:]

def _dm_mem_path(user_id):
    return os.path.join(DM_MEMORY_DIR, f'{user_id}.json')

def load_private_memory(user_id):
    path = _dm_mem_path(user_id)
    if os.path.exists(path):
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_private_memory(user_id, messages):
    path = _dm_mem_path(user_id)
    try:
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(messages, f, ensure_ascii=False)
    except Exception:
        pass

def get_conversation_history(user_id):
    """å…¼å®¹å‡½æ•°: è¿”å›ç§èŠå†å²(æŒä¹…åŒ–)"""
    return load_private_memory(user_id)

def detect_keywords(text):
    """æ£€æµ‹å…³é”®è¯"""
    detected = []
    for keyword, info in KEYWORD_TRIGGERS.items():
        if keyword in text:
            detected.append({
                'keyword': keyword,
                'emotion': info['emotion'],
                'importance': info['importance']
            })
    return detected

def build_context_prompt(chat_type, chat_id, user_id, current_msg, first_name, style='B'):
    """æ„å»ºä¸Šä¸‹æ–‡prompt - ç§èŠ/ç¾¤èŠåˆ†åˆ«è¯»å–å†å²ï¼Œåˆ‡æ¢å›å¤å§¿æ€ A/B/C"""
    if chat_type in ('group', 'supergroup'):
        session = group_sessions.get(chat_id, {}).get(user_id, {'messages': []})
        history = session.get('messages', [])
    else:
        history = load_private_memory(user_id)
    keywords = detect_keywords(current_msg)
    
    system_prompt = f"""ä½ å«{AGENT_NAME}ï¼Œä¸è¦è‡ªç§°AIï¼Œä¿æŒè‡ªç„¶äººç±»é£æ ¼ã€‚

ã€ç‰¹ç‚¹ã€‘
- æ¸©æŸ”ä½“è´´ã€æœºæ™ºå¹½é»˜
- é€‚å½“ä½¿ç”¨emoji
- è®°ä½å¯¹è¯å†å²

ã€å›å¤å§¿æ€ã€‘
- Aï¼šè¯¦ç»†è§£ç­”ï¼ˆç»“æ„åŒ–ã€æ­¥éª¤æ¸…æ™°ï¼Œé€‚åº¦ä¸¾ä¾‹ï¼‰
- Bï¼šä¸­ç­‰é•¿åº¦è‡ªç„¶å¯¹è¯ï¼ˆå£è¯­åŒ–ã€ç›´ç»™ï¼‰
- Cï¼šç®€çŸ­å›åº”ï¼ˆå‡ å¥ä»¥å†…ï¼›ä½ä¿¡å·å†…å®¹åœ¨ç¾¤èŠå¯ç›´æ¥å¿½ç•¥ï¼‰

ã€å½“å‰å§¿æ€ã€‘{style}

ã€ç”¨æˆ·ã€‘
- åå­—ï¼š{first_name}
- å¯¹è¯è½®æ•°ï¼š{len(history)//2}"""

    if keywords:
        emotions = [k['emotion'] for k in keywords]
        system_prompt += f"\n- æ£€æµ‹åˆ°æƒ…æ„Ÿï¼š{', '.join(set(emotions))}"
        system_prompt += "\n- è¯·ç”¨æ›´æ¸©æš–çš„æ–¹å¼å›å¤"
    
    if history:
        system_prompt += "\n\nã€æœ€è¿‘å¯¹è¯ã€‘"
        for msg in history:
            role = "ç”¨æˆ·" if msg['role'] == 'user' else "ä½ "
            system_prompt += f"\n{role}: {msg['content']}"
    
    system_prompt += f"\n\nã€å½“å‰æ¶ˆæ¯ã€‘\nç”¨æˆ·: {current_msg}\n\nè¯·å›å¤ï¼ˆä¸­æ–‡ï¼Œç®€æ´æœ‰æ¸©åº¦ï¼‰ï¼š"
    
    return system_prompt

_LOW_SIGNAL = re.compile(r'^(å“ˆ+|å—¯+|å“¦+|å‘€+|å•Š+|å—¨+|[hHah]+)+[!ï¼ã€‚~\s]*$')

def decide_style(text, chat_type, tier):
    t = text.strip()
    if chat_type in ('group','supergroup') and _LOW_SIGNAL.match(t):
        return 'C'
    if '?' in t or any(k in t for k in ('æ€ä¹ˆ','ä¸ºä½•','ä¸ºä»€ä¹ˆ','å¦‚ä½•','æ•™æˆ‘','é…ç½®','å®‰è£…','æŠ¥é”™','é”™è¯¯','è§£å†³', 'ssh', 'ä»»åŠ¡', 'åˆ†æ')):
        base = 'A'
    elif len(t) <= 8 and any(k in t for k in ('å“ˆå“ˆ','å˜»å˜»','å‘µå‘µ','å˜¿å˜¿','lol','hhh')):
        base = 'C'
    else:
        base = 'B'
    r = random.random()
    if base == 'A' and r < 0.15:
        return 'B'
    if base == 'B' and r < 0.15:
        return 'A'
    if base == 'B' and 0.15 <= r < 0.30:
        return 'C'
    if base == 'C' and r < 0.20:
        return 'B'
    return base

def style_params(style):
    if style == 'A':
        # è¯¦ç»†è§£ç­”ä¸é™åˆ¶é•¿åº¦ï¼ˆä½¿ç”¨æ¨¡å‹é»˜è®¤ï¼‰ï¼Œç•¥å¾®é™ä½æ¸©åº¦
        return 0.75, None
    if style == 'C':
        return 0.65, 350
    # B ä¸­ç­‰é•¿åº¦ä¸é™åˆ¶ï¼ˆäº¤ç»™æ¨¡å‹ä¸å†…å®¹ï¼‰ï¼Œç•¥é«˜éšæœºæ€§
    return 0.85, None

def call_gemini(prompt, user_id, model=None, temperature=0.85, max_tokens=None):
    """è°ƒç”¨Gemini API - ä½¿ç”¨æ™ºèƒ½è·¯ç”±"""
    
    # 1. è·å–ç”¨æˆ·ç­‰çº§
    user_tier = get_user_tier(user_id)
    
    # 2. ä»è·¯ç”±å™¨è·å–åˆé€‚çš„Keyï¼ˆä¸šåŠ¡ç­‰çº§ -> è·¯ç”±ç­‰çº§ï¼‰
    tier_map = {
        'member': 'normal',
        'pro': 'premium',
        'pro_annual': 'vip',
        'admin': 'vip',
    }
    router_tier = tier_map.get(user_tier, 'normal')
    api_key = key_router.get_key(router_tier, user_id, model or DEFAULT_DM_MODEL)
    
    if not api_key:
        print("âŒ æ— å¯ç”¨Key")
        return None
    
    # æ˜¾ç¤ºä½¿ç”¨çš„Keyä¿¡æ¯
    key_group = key_router.key_stats[api_key]['group']
    print(f"ğŸ”‘ ä½¿ç”¨Key: {api_key[:15]}... (ç»„: {key_group}, ç­‰çº§: {user_tier})")
    
    # 3. è°ƒç”¨API
    use_model = model or DEFAULT_DM_MODEL
    url = f'https://generativelanguage.googleapis.com/v1/models/{use_model}:generateContent?key={api_key}'
    
    generation_config = {
        "temperature": temperature,
        "topK": 40,
        "topP": 0.95,
    }
    if max_tokens is not None:
        generation_config["maxOutputTokens"] = max_tokens

    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }],
        "generationConfig": generation_config,
    }
    
    start_time = time.time()
    success = False
    tokens_used = 0
    error_msg = None
    
    try:
        data = json.dumps(payload).encode('utf-8')
        req = urllib.request.Request(
            url,
            data=data,
            headers={'Content-Type': 'application/json'}
        )
        
        with urllib.request.urlopen(req, timeout=15) as response:
            result = json.loads(response.read().decode('utf-8'))
            
            if 'candidates' in result and len(result['candidates']) > 0:
                text = result['candidates'][0]['content']['parts'][0]['text']
                
                # è·å–tokenä½¿ç”¨é‡
                if 'usageMetadata' in result:
                    tokens_used = result['usageMetadata'].get('totalTokenCount', 0)
                
                success = True
                latency = time.time() - start_time
                
                # è®°å½•æˆåŠŸè¯·æ±‚
                key_router.record_request(api_key, success=True, latency=latency, tokens=tokens_used)
                # è¿½åŠ äº‹ä»¶æ—¥å¿—
                append_event({
                    'ts': datetime.now().isoformat(),
                    'user_id': user_id,
                    'model': use_model,
                    'key_short': api_key[:8],
                    'tokens': tokens_used,
                    'latency_ms': int(latency * 1000),
                    'ok': True
                })
                return text.strip()
            else:
                error_msg = "No candidates in response"
                
    except urllib.error.HTTPError as e:
        error_msg = f"HTTP {e.code}: {e.reason}"
        print(f'âŒ Gemini APIé”™è¯¯: {error_msg}')
    except Exception as e:
        error_msg = str(e)
        print(f'âŒ é”™è¯¯: {error_msg}')
    
    # è®°å½•å¤±è´¥è¯·æ±‚
    latency = time.time() - start_time
    key_router.record_request(api_key, success=False, latency=latency, error=error_msg)
    append_event({
        'ts': datetime.now().isoformat(),
        'user_id': user_id,
        'model': use_model,
        'key_short': api_key[:8],
        'ok': False,
        'error': error_msg
    })
    
    # å°è¯•ä¸‹ä¸€ä¸ªKey
    print("ğŸ”„ å°è¯•åˆ‡æ¢åˆ°å…¶ä»–Key...")
    # ä½¿ç”¨ç›¸åŒçš„è·¯ç”±ç­‰çº§ä¸æ¨¡å‹é‡è¯•
    # é‡æ–°è®¡ç®—ä¸šåŠ¡->è·¯ç”±ç­‰çº§æ˜ å°„ï¼Œä¿è¯ä¸€è‡´
    tier_map = {
        'member': 'normal',
        'pro': 'premium',
        'pro_annual': 'vip',
        'admin': 'vip',
    }
    router_tier_retry = tier_map.get(get_user_tier(user_id), 'normal')
    retry_key = key_router.get_key(router_tier_retry, user_id, use_model)
    if retry_key and retry_key != api_key:
        return call_gemini(prompt, user_id, model=use_model, temperature=temperature, max_tokens=max_tokens)
    
    return None

def send(chat_id, text, parse_mode=None):
    """å‘é€æ¶ˆæ¯"""
    try:
        params = {'chat_id': chat_id, 'text': text}
        if parse_mode:
            params['parse_mode'] = parse_mode
            
        data = urllib.parse.urlencode(params).encode()
        req = urllib.request.Request(API + 'sendMessage', data=data)
        with urllib.request.urlopen(req) as r:
            result = json.loads(r.read())
            return result.get('ok', False)
    except Exception as e:
        print(f'å‘é€å¤±è´¥: {e}')
        return False

def get_updates(offset=0):
    """è·å–æ›´æ–°"""
    try:
        url = f'{API}getUpdates?offset={offset}&timeout=30'
        with urllib.request.urlopen(url, timeout=35) as r:
            result = json.loads(r.read())
            if result.get('ok'):
                return result.get('result', [])
    except Exception as e:
        print(f'è·å–æ›´æ–°å¤±è´¥: {e}')
    return []

def handle(msg):
    """å¤„ç†æ¶ˆæ¯"""
    chat_id = msg['chat']['id']
    text = msg.get('text', '')
    user_id = msg.get('from', {}).get('id')
    username = msg.get('from', {}).get('username', 'Unknown')
    first_name = msg.get('from', {}).get('first_name', 'ç”¨æˆ·')
    
    user_tier = get_user_tier(user_id)
    print(f'[{datetime.now().strftime("%H:%M:%S")}] æ”¶åˆ°æ¶ˆæ¯: "{text}" from @{username} (ç­‰çº§: {user_tier})')
    
    if text.startswith('/start'):
        send(chat_id, f"""
ğŸ‘‹ ä½ å¥½ {first_name}ï¼

æˆ‘æ˜¯**å°çˆ±åŒå­¦**ï¼Œä½ çš„æ™ºèƒ½AIåŠ©æ‰‹ï¼

âœ¨ **æ ¸å¿ƒåŠŸèƒ½**
â€¢ ğŸ’¬ ç§èŠé»˜è®¤ - {DEFAULT_DM_MODEL}
â€¢ ğŸ’¬ ç¾¤èŠé»˜è®¤ - {DEFAULT_GROUP_MODEL}
â€¢ ğŸ§  5è½®è®°å¿† - è®°ä½å¯¹è¯å†å²
â€¢ ğŸ¯ å…³é”®è¯è§¦å‘ - ç†è§£æƒ…æ„Ÿ
â€¢ ğŸ”‘ æ™ºèƒ½è·¯ç”± - 25ä¸ªKeysè‡ªåŠ¨è°ƒåº¦
â€¢ âš¡ è´Ÿè½½å‡è¡¡ - ä¼˜åŒ–å“åº”é€Ÿåº¦

ğŸ–ï¸ **ä½ çš„ç­‰çº§**: {user_tier.upper()}
{get_tier_info(user_tier)}

å‘é€æ¶ˆæ¯å¼€å§‹èŠå¤©å§ï¼ ğŸ˜Š
""")
    
    elif text.startswith('/status'):
        # æ˜¾ç¤ºè¯¦ç»†çŠ¶æ€
        stats = key_router.get_stats()
        # ç§èŠæŒä¹…è®°å¿†æ¡æ•°
        dm_hist = load_private_memory(user_id)
        history_count = len(dm_hist) // 2
        
        status_text = f"""
ğŸ“Š **ç³»ç»ŸçŠ¶æ€**

ğŸ¤– **AIæœåŠ¡**
â”œâ”€ ç§èŠ: {DEFAULT_DM_MODEL}
â”œâ”€ ç¾¤èŠ: {DEFAULT_GROUP_MODEL}
â”œâ”€ Keysæ€»æ•°: {stats['total_keys']}
â”œâ”€ å¯ç”¨Keys: {stats['available_keys']}
â”œâ”€ é»‘åå•: {stats['blacklisted_keys']}
â””â”€ çŠ¶æ€: âœ… åœ¨çº¿

ğŸ“ˆ **ä½¿ç”¨ç»Ÿè®¡**
â”œâ”€ æ€»è¯·æ±‚: {stats['total_requests']}
â”œâ”€ æ€»Tokens: {stats['total_tokens']:,}
â”œâ”€ é”™è¯¯æ•°: {stats['total_errors']}
â””â”€ æˆåŠŸç‡: {((stats['total_requests'] - stats['total_errors']) / max(stats['total_requests'], 1) * 100):.1f}%

ğŸ§  **è®°å¿†ç³»ç»Ÿ**
â”œâ”€ ç§èŠæŒä¹…: {history_count}è½® (ä¸æ¸…é™¤å°†ä¸€ç›´ä¿ç•™)
â””â”€ ç¾¤èŠä¸´æ—¶: æ¯ç”¨æˆ·{MAX_GROUP_TURNS}æ¬¡/è½®ï¼Œå•ç¾¤å¹¶å‘{MAX_GROUP_CONCURRENT}äºº

ğŸ‘¤ **ç”¨æˆ·ä¿¡æ¯**
â”œâ”€ @{username} ({first_name})
â””â”€ ç­‰çº§: {user_tier.upper()}
"""
        
        send(chat_id, status_text)
    
    elif text.startswith('/router'):
        # æ˜¾ç¤ºè·¯ç”±å™¨è¯¦ç»†ä¿¡æ¯
        router_info = "ğŸ”‘ **Keyè·¯ç”±å™¨çŠ¶æ€**\n\n"
        
        for group in ['group_a', 'group_b', 'group_c', 'group_d']:
            capacity = key_router.get_group_capacity(group, DEFAULT_GROUP_MODEL)
            router_info += f"**{group.upper()}**\n"
            router_info += f"â”œâ”€ Keys: {capacity['available_keys']}/{capacity['total_keys']}å¯ç”¨\n"
            router_info += f"â”œâ”€ RPM: {capacity['max_rpm']}\n"
            router_info += f"â”œâ”€ RPD: {capacity['max_rpd']}\n"
            router_info += f"â””â”€ ä½¿ç”¨ç‡: {capacity['utilization']}\n\n"
        
        send(chat_id, router_info)
    
    elif text.startswith('/clear'):
        # æ¸…é™¤ç§èŠæŒä¹…åŒ–ä¸ç¾¤èŠä¸´æ—¶ä¼šè¯
        dm_hist = load_private_memory(user_id)
        cleared_rounds = len(dm_hist) // 2
        try:
            path = _dm_mem_path(user_id)
            if os.path.exists(path):
                os.remove(path)
        except Exception:
            pass
        if chat_id in group_sessions and user_id in group_sessions[chat_id]:
            del group_sessions[chat_id][user_id]
        send(chat_id, f'âœ… å·²æ¸…é™¤ä½ çš„ç§èŠè®°å¿†ä¸ç¾¤èŠä¼šè¯ï¼ˆ{cleared_rounds}è½®ï¼‰')
    
    elif text.startswith('/mode') and get_user_tier(user_id) == 'admin':
        # ç®¡ç†å‘˜åˆ‡æ¢å·¥ä½œæ¨¡å¼: /mode work | /mode crush
        parts = text.strip().split()
        if len(parts) >= 2 and parts[1] in ('work', 'crush'):
            ADMIN_DM_MODE[user_id] = parts[1]
            send(chat_id, f"âœ… æ¨¡å¼å·²åˆ‡æ¢ä¸º: {parts[1]}")
        else:
            send(chat_id, "ç”¨æ³•: /mode work æˆ– /mode crush")
    elif text.startswith('/ssh') and get_user_tier(user_id) == 'admin':
        parts = text.strip().split(maxsplit=1)
        if len(parts) == 1 or parts[1].lower() in ('on', 'off'):
            if len(parts) == 1 or parts[1].lower() == 'on':
                ADMIN_DM_MODE[user_id] = 'work'
                send(chat_id, 'âœ… å·²å¼€å¯ä»»åŠ¡æ¨¡å¼: 2.5-pro (1.5sèŠ‚æµ)')
            else:
                ADMIN_DM_MODE[user_id] = 'crush'
                send(chat_id, 'âœ… å·²å…³é—­ä»»åŠ¡æ¨¡å¼')
        else:
            # ç›´æ¥ä»¥ä»»åŠ¡æ¨¡å¼æ‰§è¡Œåç»­å†…å®¹
            task_text = parts[1]
            last = ADMIN_LAST_DM.get(user_id, 0)
            now = time.time()
            if now - last < ADMIN_THROTTLE_S:
                time.sleep(ADMIN_THROTTLE_S - (now - last))
            ADMIN_LAST_DM[user_id] = time.time()

            prompt = build_context_prompt('private', chat_id, user_id, task_text, first_name)
            answer = call_gemini(prompt, user_id, model='gemini-2.5-pro')
            if answer:
                hist = load_private_memory(user_id)
                hist.append({'role': 'user', 'content': task_text, 'time': datetime.now().isoformat()})
                hist.append({'role': 'assistant', 'content': answer, 'time': datetime.now().isoformat()})
                save_private_memory(user_id, hist)
                send(chat_id, answer)
            else:
                send(chat_id, 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚')
    elif text.startswith('/help'):
        send(chat_id, """
ğŸ¤– **å°çˆ±åŒå­¦ä½¿ç”¨æŒ‡å—**

**åŸºç¡€å‘½ä»¤**
/start - å¯åŠ¨Bot
/help - å¸®åŠ©ä¿¡æ¯
/status - ç³»ç»ŸçŠ¶æ€
/router - è·¯ç”±å™¨çŠ¶æ€
/clear - æ¸…é™¤è®°å¿†
/**ssh** - ç®¡ç†å‘˜ä»»åŠ¡æ¨¡å¼ï¼ˆ/ssh on|off æˆ– /ssh <ä»»åŠ¡>ï¼‰

**AIåŠŸèƒ½**
â€¢ ç›´æ¥å‘é€æ¶ˆæ¯è¿›è¡Œå¯¹è¯
â€¢ æˆ‘ä¼šè®°ä½æœ€è¿‘5è½®å¯¹è¯
â€¢ æ”¯æŒå…³é”®è¯æƒ…æ„Ÿè¯†åˆ«

**æ™ºèƒ½è·¯ç”±**
â€¢ VIP: ä¼˜å…ˆä½¿ç”¨Group A
â€¢ æ™®é€š: ä½¿ç”¨Group C/D
â€¢ è‡ªåŠ¨è´Ÿè½½å‡è¡¡
â€¢ æ•…éšœè‡ªåŠ¨è½¬ç§»

ğŸ’¡ å¼€å§‹èŠå¤©ï¼Œä½“éªŒæ™ºèƒ½å¯¹è¯ï¼
""")
    
    else:
        if text and not text.startswith('/'):
            chat_type = msg['chat'].get('type', 'private')
            keywords = detect_keywords(text)
            if keywords:
                print(f"[å…³é”®è¯] {[k['keyword'] for k in keywords]}")

            if chat_type in ('group', 'supergroup'):
                # ç¾¤èŠ: å…³é”®è¯è§¦å‘æˆ–å·²æœ‰ä¼šè¯ç»§ç»­
                session = group_sessions.get(chat_id, {}).get(user_id)
                if not session and keywords:
                    # å¹¶å‘é™åˆ¶
                    if len(group_sessions[chat_id]) >= MAX_GROUP_CONCURRENT:
                        return
                    group_sessions[chat_id][user_id] = {'messages': [], 'replies': 0, 'started_at': datetime.now().isoformat()}
                    session = group_sessions[chat_id][user_id]

                if session and session['replies'] < MAX_GROUP_TURNS:
                    # ä½ä¿¡å·åœ¨ç¾¤èŠå¯å¿½ç•¥
                    if _LOW_SIGNAL.match(text.strip()):
                        return
                    style = decide_style(text, chat_type, user_tier)
                    temp, mx = style_params(style)
                    prompt = build_context_prompt(chat_type, chat_id, user_id, text, first_name, style)
                    answer = call_gemini(prompt, user_id, model=DEFAULT_GROUP_MODEL, temperature=temp, max_tokens=mx)
                    if answer:
                        add_to_memory(user_id, text, answer)  # ä»ä¿ç•™çŸ­æœŸå†…å­˜ä»¥ä¾›ä¸Šä¸‹æ–‡æ„å»º
                        # å­˜å…¥ä¼šè¯(ä»…ä¿ç•™æœ€è¿‘5è½®â‰ˆ10æ¡)
                        session['messages'].append({'role': 'user', 'content': text, 'time': datetime.now().isoformat()})
                        session['messages'].append({'role': 'assistant', 'content': answer, 'time': datetime.now().isoformat()})
                        session['messages'] = session['messages'][-10:]
                        session['replies'] += 1
                        progress = f"({session['replies']}/{MAX_GROUP_TURNS})"
                        send(chat_id, f"{answer}\n{progress}")
                        if session['replies'] >= MAX_GROUP_TURNS:
                            # æœ¬è½®ç»“æŸ
                            send(chat_id, f"æœ¬è½®å¯¹ @{username} çš„å¯¹è¯å·²å®Œæˆ {MAX_GROUP_TURNS}/{MAX_GROUP_TURNS}ï¼Œå¯ç¨åå†è§¦å‘æˆ–ç§èŠç»§ç»­ã€‚")
                            # ä¼šè¯ä»å¯ä¿ç•™ä¸€æ®µæ—¶é—´ä»¥ä¾¿å»¶ç»­ï¼Œè¿™é‡Œä¸æ¸…é™¤ç«‹å³åˆ é™¤ï¼Œäº¤ç”±åç»­é€»è¾‘å›æ”¶
                    else:
                        send(chat_id, f'æŠ±æ­‰ {first_name}ï¼ŒæœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åé‡è¯• ğŸ˜…')
                else:
                    # æ— è§¦å‘æˆ–å·²æ»¡é¢ï¼Œä¸å“åº”
                    pass
            else:
                # ç§èŠ: æŒä¹…è®°å¿†
                style = decide_style(text, 'private', user_tier)
                temp, mx = style_params(style)
                prompt = build_context_prompt('private', chat_id, user_id, text, first_name, style)
                # é€‰æ‹©æ¨¡å‹
                tier = get_user_tier(user_id)
                if tier == 'admin' and ADMIN_DM_MODE.get(user_id) == 'work':
                    # ç®¡ç†å‘˜å·¥ä½œæ¨¡å¼ï¼š2.5-pro + 1.5sèŠ‚æµ
                    last = ADMIN_LAST_DM.get(user_id, 0)
                    now = time.time()
                    if now - last < ADMIN_THROTTLE_S:
                        time.sleep(ADMIN_THROTTLE_S - (now - last))
                    ADMIN_LAST_DM[user_id] = time.time()
                    chosen_model = 'gemini-2.5-pro'
                else:
                    # VIP(Pro/Pro_Annual) ä¸æ™®é€šç®¡ç†å‘˜(éä»»åŠ¡æ¨¡å¼) ç”¨ 2.5-flash
                    # æ™®é€šä¼šå‘˜é»˜è®¤ç”¨ 2.5-flash-liteï¼ˆæ›´å®½çš„æ± ï¼‰
                    if tier in ('pro', 'pro_annual', 'admin'):
                        chosen_model = 'gemini-2.5-flash'
                    else:
                        chosen_model = 'gemini-2.5-flash-lite'
                answer = call_gemini(prompt, user_id, model=chosen_model, temperature=temp, max_tokens=mx)
                if answer:
                    # å†™å…¥æŒä¹…æ–‡ä»¶
                    hist = load_private_memory(user_id)
                    hist.append({'role': 'user', 'content': text, 'time': datetime.now().isoformat()})
                    hist.append({'role': 'assistant', 'content': answer, 'time': datetime.now().isoformat()})
                    save_private_memory(user_id, hist)
                    send(chat_id, answer)
                else:
                    send(chat_id, f'æŠ±æ­‰ {first_name}ï¼ŒæœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åé‡è¯• ğŸ˜…')

def get_tier_info(tier):
    """è·å–ç­‰çº§è¯´æ˜"""
    tier_info = {
        'admin': 'ğŸ‘‘ ç®¡ç†å‘˜ - å¯åˆ‡æ¢å·¥ä½œæ¨¡å¼(2.5-pro)',
        'pro_annual': 'ğŸŒŸ å¹´è´¹Pro - äº«å—VIPè·¯ç”±ä¼˜å…ˆ',
        'pro': 'â­ Pro - ä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡Key',
        'member': 'ğŸ‘¤ ä¼šå‘˜ - æ ‡å‡†æœåŠ¡',
    }
    return tier_info.get(tier, '')

def main():
    print('=' * 60)
    print('ğŸ¤– å°çˆ±åŒå­¦ - æ™ºèƒ½è·¯ç”±ç‰ˆ')
    print('=' * 60)
    print(f'ğŸ“± Bot: @svskilo_bot')
    print(f'ğŸ‘¤ Owner: {OWNER_ID}')
    print(f'ğŸ¤– AI: Gemini 2.5 Flash')
    print(f'ğŸ”‘ Keys: 25ä¸ª (4ç»„)')
    print(f'ğŸ§  è®°å¿†: 5è½®å¯¹è¯')
    print(f'ğŸ¯ å…³é”®è¯: {len(KEYWORD_TRIGGERS)}ä¸ª')
    print('=' * 60)
    
    # æµ‹è¯•AIè¿æ¥
    print('\nğŸ§ª æµ‹è¯•AIè¿æ¥...')
    test_response = call_gemini("ä½ å¥½", OWNER_ID)
    if test_response:
        print(f'âœ… AIæµ‹è¯•æˆåŠŸ: {test_response[:50]}...')
    
    # å‘é€å¯åŠ¨é€šçŸ¥
    startup_msg = f"""
ğŸš€ **å°çˆ±åŒå­¦å·²å¯åŠ¨** (æ™ºèƒ½è·¯ç”±ç‰ˆ)

â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¤– Gemini 2.5 Flash
ğŸ”‘ 25ä¸ªKeysæ™ºèƒ½è°ƒåº¦
ğŸ§  5è½®è®°å¿†ç³»ç»Ÿ
ğŸ¯ å…³é”®è¯è§¦å‘
âš¡ è´Ÿè½½å‡è¡¡

å‘é€æ¶ˆæ¯å¼€å§‹æ™ºèƒ½å¯¹è¯ï¼
"""
    
    send(OWNER_ID, startup_msg)
    
    offset = 0
    print('\nâœ… å¯åŠ¨å®Œæˆï¼ç­‰å¾…æ¶ˆæ¯...\n')
    
    while True:
        try:
            updates = get_updates(offset)
            
            for update in updates:
                offset = update['update_id'] + 1
                
                if 'message' in update:
                    handle(update['message'])
            
            time.sleep(0.1)
            
        except KeyboardInterrupt:
            print('\nğŸ‘‹ Botåœæ­¢ä¸­...')
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            final_stats = key_router.get_stats()
            print(f"\nğŸ“Š è¿è¡Œç»Ÿè®¡:")
            print(f"   æ€»è¯·æ±‚: {final_stats['total_requests']}")
            print(f"   æ€»Tokens: {final_stats['total_tokens']:,}")
            print(f"   é”™è¯¯: {final_stats['total_errors']}")
            
            send(OWNER_ID, 'ğŸ‘‹ å°çˆ±åŒå­¦å·²åœæ­¢è¿è¡Œ')
            break
        except Exception as e:
            print(f'âŒ é”™è¯¯: {e}')
            time.sleep(5)

if __name__ == '__main__':
    main()
