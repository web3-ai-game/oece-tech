#!/usr/bin/env python3
"""
å…¨é¢æµ‹è¯•æ‰€æœ‰Geminiæ¨¡å‹
å¯¹æ¯”å…è´¹å±‚å’Œä»˜è´¹å±‚è´¦æˆ·å·®å¼‚
"""

import requests
import time
import json
from datetime import datetime
from typing import Dict, List, Optional
from collections import defaultdict

# æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼ˆåŸºäºæˆªå›¾ï¼‰
ALL_MODELS = {
    # æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
    "text_models": [
        "gemini-2.5-pro",
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
        "gemini-2.0-flash-exp",
    ],
    # å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹
    "multimodal_models": [
        "gemini-2.0-flash-preview-image-generation",
        "gemini-2.5-flash-tts",
    ],
    # Live APIæ¨¡å‹
    "live_models": [
        "gemini-2.0-flash-live",
        "gemini-2.5-flash-live",
        "gemini-2.5-flash-native-audio-dialog",
    ],
    # å®éªŒæ¨¡å‹
    "experimental_models": [
        "learnlm-2.0-flash-experimental",
        "gemini-robotics-er-1.5-preview",
    ],
    # å›¾åƒç”Ÿæˆ
    "image_models": [
        "imagen-3.0-generate",
    ],
    # è§†é¢‘ç”Ÿæˆ
    "video_models": [
        "veo-2.0-generate-001",
    ]
}

# Keysåˆ†ç±»ï¼ˆåŸºäºç”¨æˆ·æä¾›ï¼‰
TEST_KEYS = {
    "free_tier": [
        # å…è´¹å±‚Keysï¼ˆä¹‹å‰æµ‹è¯•çš„25ä¸ªä¸­é€‰10ä¸ªï¼‰
        "AIzaSyA5PgAqHpLt8yHCcxdTyBTHt_YP9VmOwjA",
        "AIzaSyDNpOIB0nn4YcVTG9x559O3Ht-AdnHUiLA",
        "AIzaSyCPxNPKzWp29Bfn41KhfGzor8Nw98UBUlU",
        "AIzaSyAWpD1-bJIE6lXv3lwT-yePeb2faEpYXd8",
        "AIzaSyBKOla-lFvzYBnMozGcqJvGMWD_A3BkpMs",
    ],
    "paid_tier": [
        # ç”¨æˆ·ä¹‹å‰æåˆ°çš„ä»˜è´¹å±‚Keys
        "AIzaSyCFsMpRhiwm_SMgsJNODRAR86NKDxM6M8c",
        "AIzaSyAt0PUYuIrHN898bGAE1amOsUjP3ogrXiQ",
    ]
}

def test_text_model(key: str, model: str) -> Dict:
    """æµ‹è¯•æ–‡æœ¬ç”Ÿæˆæ¨¡å‹"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={key}"
    
    payload = {
        "contents": [{
            "parts": [{"text": "Say hi"}]
        }],
        "generationConfig": {
            "maxOutputTokens": 5,
            "temperature": 0
        }
    }
    
    try:
        start = time.time()
        response = requests.post(url, json=payload, timeout=10)
        elapsed = time.time() - start
        
        # è·å–å“åº”å¤´ä¿¡æ¯
        headers = dict(response.headers)
        
        result = {
            "model": model,
            "status": response.status_code,
            "response_time": round(elapsed, 2),
            "rate_limit_info": {
                "rpm_limit": headers.get('X-RateLimit-Limit-Requests', 'N/A'),
                "rpm_remaining": headers.get('X-RateLimit-Remaining-Requests', 'N/A'),
                "tpm_limit": headers.get('X-RateLimit-Limit-Tokens', 'N/A'),
                "tpm_remaining": headers.get('X-RateLimit-Remaining-Tokens', 'N/A'),
            },
            "success": response.status_code == 200,
            "error": None if response.status_code == 200 else response.text[:200]
        }
        
        if response.status_code == 200:
            try:
                data = response.json()
                if 'candidates' in data:
                    result["response_text"] = data['candidates'][0]['content']['parts'][0]['text'][:50]
            except:
                pass
        
        return result
        
    except Exception as e:
        return {
            "model": model,
            "status": -1,
            "response_time": 0,
            "success": False,
            "error": str(e)
        }

def test_image_model(key: str, model: str) -> Dict:
    """æµ‹è¯•å›¾åƒç”Ÿæˆæ¨¡å‹"""
    # imagenä½¿ç”¨ä¸åŒçš„endpoint
    if "imagen" in model:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}?key={key}"
    else:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={key}"
    
    payload = {
        "prompt": "A simple test image",
        "numberOfImages": 1
    }
    
    try:
        start = time.time()
        response = requests.post(url, json=payload, timeout=15)
        elapsed = time.time() - start
        
        return {
            "model": model,
            "status": response.status_code,
            "response_time": round(elapsed, 2),
            "success": response.status_code == 200,
            "error": None if response.status_code == 200 else response.text[:200]
        }
    except Exception as e:
        return {
            "model": model,
            "status": -1,
            "response_time": 0,
            "success": False,
            "error": str(e)
        }

def comprehensive_test():
    """å…¨é¢æµ‹è¯•æ‰€æœ‰æ¨¡å‹"""
    print("ğŸ” å¼€å§‹å…¨é¢æµ‹è¯•Geminiæ¨¡å‹")
    print("=" * 80)
    
    results = {
        "timestamp": datetime.now().isoformat(),
        "free_tier": {},
        "paid_tier": {}
    }
    
    # æµ‹è¯•å…è´¹å±‚
    print("\nğŸ“Š æµ‹è¯•å…è´¹å±‚Keys")
    print("-" * 80)
    for i, key in enumerate(TEST_KEYS["free_tier"][:2], 1):  # åªæµ‹å‰2ä¸ªé¿å…è¿‡åº¦
        print(f"\nå…è´¹å±‚Key #{i}: {key[:20]}...")
        results["free_tier"][f"key_{i}"] = {
            "key_display": key[:20] + "...",
            "models": {}
        }
        
        # æµ‹è¯•æ–‡æœ¬æ¨¡å‹
        print("  æµ‹è¯•æ–‡æœ¬æ¨¡å‹:")
        for model in ALL_MODELS["text_models"]:
            print(f"    - {model}...", end=" ")
            result = test_text_model(key, model)
            results["free_tier"][f"key_{i}"]["models"][model] = result
            
            if result["success"]:
                print(f"âœ… ({result['response_time']}s)")
            elif result["status"] == 429:
                print(f"âš ï¸ 429é™æµ")
            else:
                print(f"âŒ {result['status']}")
            
            time.sleep(1)  # é¿å…å¤ªå¿«
    
    # æµ‹è¯•ä»˜è´¹å±‚
    print("\n\nğŸ’° æµ‹è¯•ä»˜è´¹å±‚Keys")
    print("-" * 80)
    for i, key in enumerate(TEST_KEYS["paid_tier"], 1):
        print(f"\nä»˜è´¹å±‚Key #{i}: {key[:20]}...")
        results["paid_tier"][f"key_{i}"] = {
            "key_display": key[:20] + "...",
            "models": {}
        }
        
        # æµ‹è¯•æ–‡æœ¬æ¨¡å‹
        print("  æµ‹è¯•æ–‡æœ¬æ¨¡å‹:")
        for model in ALL_MODELS["text_models"]:
            print(f"    - {model}...", end=" ")
            result = test_text_model(key, model)
            results["paid_tier"][f"key_{i}"]["models"][model] = result
            
            if result["success"]:
                print(f"âœ… ({result['response_time']}s)")
            elif result["status"] == 429:
                print(f"âš ï¸ 429é™æµ â† é‡ç‚¹å…³æ³¨!")
            elif result["status"] == 403:
                print(f"âŒ 403æ— æƒé™")
            else:
                print(f"âŒ {result['status']}")
            
            time.sleep(1)
    
    # ä¿å­˜ç»“æœ
    with open("comprehensive_model_test.json", "w") as f:
        json.dump(results, f, indent=2)
    
    return results

def analyze_results(results: Dict):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print("\n\nğŸ“ˆ æµ‹è¯•ç»“æœåˆ†æ")
    print("=" * 80)
    
    # ç»Ÿè®¡å…è´¹å±‚
    print("\nğŸ†“ å…è´¹å±‚ç»Ÿè®¡:")
    free_stats = defaultdict(lambda: {"success": 0, "total": 0, "429": 0})
    
    for key_data in results["free_tier"].values():
        for model, result in key_data["models"].items():
            free_stats[model]["total"] += 1
            if result["success"]:
                free_stats[model]["success"] += 1
            elif result["status"] == 429:
                free_stats[model]["429"] += 1
    
    for model, stats in free_stats.items():
        success_rate = (stats["success"] / stats["total"] * 100) if stats["total"] > 0 else 0
        print(f"  {model:40s} æˆåŠŸç‡: {success_rate:5.1f}%  429é”™è¯¯: {stats['429']}")
    
    # ç»Ÿè®¡ä»˜è´¹å±‚
    print("\nğŸ’° ä»˜è´¹å±‚ç»Ÿè®¡:")
    paid_stats = defaultdict(lambda: {"success": 0, "total": 0, "429": 0, "403": 0})
    
    for key_data in results["paid_tier"].values():
        for model, result in key_data["models"].items():
            paid_stats[model]["total"] += 1
            if result["success"]:
                paid_stats[model]["success"] += 1
            elif result["status"] == 429:
                paid_stats[model]["429"] += 1
            elif result["status"] == 403:
                paid_stats[model]["403"] += 1
    
    for model, stats in paid_stats.items():
        success_rate = (stats["success"] / stats["total"] * 100) if stats["total"] > 0 else 0
        status = "âœ…" if stats["success"] > 0 else "âŒ"
        print(f"  {status} {model:40s} æˆåŠŸç‡: {success_rate:5.1f}%  429: {stats['429']}  403: {stats['403']}")
    
    # å¯¹æ¯”åˆ†æ
    print("\nğŸ”„ å…è´¹å±‚ vs ä»˜è´¹å±‚å¯¹æ¯”:")
    print("-" * 80)
    
    all_models = set(free_stats.keys()) | set(paid_stats.keys())
    for model in sorted(all_models):
        free_ok = free_stats[model]["success"] > 0 if model in free_stats else False
        paid_ok = paid_stats[model]["success"] > 0 if model in paid_stats else False
        
        if free_ok and paid_ok:
            print(f"  âœ… {model:40s} ä¸¤è€…éƒ½å¯ç”¨")
        elif free_ok:
            print(f"  ğŸ†“ {model:40s} ä»…å…è´¹å±‚å¯ç”¨")
        elif paid_ok:
            print(f"  ğŸ’° {model:40s} ä»…ä»˜è´¹å±‚å¯ç”¨")
        else:
            print(f"  âŒ {model:40s} ä¸¤è€…éƒ½ä¸å¯ç”¨")
    
    # 429é”™è¯¯åˆ†æ
    print("\nâš ï¸ 429é™æµé”™è¯¯åˆ†æ:")
    print("-" * 80)
    
    free_429_count = sum(stats["429"] for stats in free_stats.values())
    paid_429_count = sum(stats["429"] for stats in paid_stats.values())
    
    print(f"  å…è´¹å±‚429é”™è¯¯æ€»æ•°: {free_429_count}")
    print(f"  ä»˜è´¹å±‚429é”™è¯¯æ€»æ•°: {paid_429_count}")
    
    if paid_429_count > 0:
        print(f"\n  âš ï¸ è­¦å‘Š: ä»˜è´¹å±‚å‡ºç°{paid_429_count}æ¬¡429é”™è¯¯ï¼Œå¯èƒ½:")
        print(f"     1. ä»˜è´¹å±‚é…é¢å·²ç”¨å®Œ")
        print(f"     2. ä»˜è´¹å±‚å®é™…æ˜¯å…è´¹å±‚")
        print(f"     3. è´¦æˆ·è¢«é™æµ")

def generate_recommendations(results: Dict):
    """ç”Ÿæˆä½¿ç”¨å»ºè®®"""
    print("\n\nğŸ’¡ ä½¿ç”¨å»ºè®®")
    print("=" * 80)
    
    # åˆ†æå“ªäº›æ¨¡å‹å¯ç”¨
    available_models = {
        "free": [],
        "paid": [],
        "both": []
    }
    
    for key_data in results["free_tier"].values():
        for model, result in key_data["models"].items():
            if result["success"] and model not in available_models["free"]:
                available_models["free"].append(model)
    
    for key_data in results["paid_tier"].values():
        for model, result in key_data["models"].items():
            if result["success"] and model not in available_models["paid"]:
                available_models["paid"].append(model)
    
    both = set(available_models["free"]) & set(available_models["paid"])
    available_models["both"] = list(both)
    
    print("\n1ï¸âƒ£ æ¨èä½¿ç”¨å…è´¹å±‚Keys:")
    for model in available_models["free"]:
        if model in available_models["both"]:
            print(f"   âœ… {model} (å…è´¹å±‚å’Œä»˜è´¹å±‚éƒ½å¯ç”¨)")
        else:
            print(f"   ğŸ†“ {model} (ä»…å…è´¹å±‚)")
    
    print("\n2ï¸âƒ£ ä»˜è´¹å±‚KeysçŠ¶æ€:")
    if len(available_models["paid"]) == 0:
        print("   âŒ ä»˜è´¹å±‚Keyså¯èƒ½æ— æ•ˆæˆ–é…é¢ç”¨å®Œ")
        print("   ğŸ’¡ å»ºè®®: ä¸“æ³¨ä½¿ç”¨å…è´¹å±‚Keys")
    else:
        for model in available_models["paid"]:
            if model not in available_models["both"]:
                print(f"   ğŸ’° {model} (ä»…ä»˜è´¹å±‚)")
    
    print("\n3ï¸âƒ£ æœ€ç»ˆå»ºè®®:")
    print("   â€¢ å…è´¹å±‚25ä¸ªKeyså·²è¶³å¤Ÿä½¿ç”¨")
    print("   â€¢ ä»˜è´¹å±‚ä¸å»ºè®®ä½¿ç”¨ï¼ˆé™¤éç¡®è®¤é…é¢å……è¶³ï¼‰")
    print("   â€¢ é‡‡ç”¨ä¿å®ˆç­–ç•¥: 10ä¸ªå…è´¹Keysè½®æ¢ä½¿ç”¨")
    print("   â€¢ æ¯Keyé™åˆ¶10 RPMï¼Œé¿å…è§¦å‘429")

def main():
    """ä¸»å‡½æ•°"""
    # è¿è¡Œå…¨é¢æµ‹è¯•
    results = comprehensive_test()
    
    # åˆ†æç»“æœ
    analyze_results(results)
    
    # ç”Ÿæˆå»ºè®®
    generate_recommendations(results)
    
    print("\nâœ… æµ‹è¯•å®Œæˆ! è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° comprehensive_model_test.json")

if __name__ == "__main__":
    main()
