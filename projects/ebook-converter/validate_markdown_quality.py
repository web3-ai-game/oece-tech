#!/usr/bin/env python3
"""
Markdown Quality Validator
æª¢æŸ¥è½‰æ›å¾Œçš„ Markdown æ–‡ä»¶è³ªé‡ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢ºå†ä¿å­˜
"""
import os
import re
import sys
from pathlib import Path
from datetime import datetime, timedelta
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class MarkdownQualityValidator:
    def __init__(self, output_dir: str = "/home/sms/ebook-converter/data/markdown-output"):
        self.output_dir = Path(output_dir)
        self.issues = []
        self.passed = []
        
    def validate_file(self, filepath: Path) -> dict:
        """Validate a single Markdown file"""
        result = {
            'file': filepath.name,
            'path': str(filepath),
            'size': filepath.stat().st_size,
            'issues': [],
            'passed': True
        }
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
        except Exception as e:
            result['issues'].append(f"ç„¡æ³•è®€å–æ–‡ä»¶: {e}")
            result['passed'] = False
            return result
        
        # 1. æª¢æŸ¥æ–‡ä»¶å¤§å°
        if len(content) < 500:
            result['issues'].append(f"å…§å®¹éçŸ­ ({len(content)} å­—ç¬¦)")
            result['passed'] = False
        
        # 2. æª¢æŸ¥æ˜¯å¦æœ‰æ¨™é¡Œçµæ§‹
        has_h1 = bool(re.search(r'^# .+', content, re.MULTILINE))
        has_h2 = bool(re.search(r'^## .+', content, re.MULTILINE))
        has_h3 = bool(re.search(r'^### .+', content, re.MULTILINE))
        
        if not has_h1 and not has_h2:
            result['issues'].append("ç¼ºå°‘æ¨™é¡Œçµæ§‹ (ç„¡ # æˆ– ## æ¨™è¨˜)")
            result['passed'] = False
        
        # 3. æª¢æŸ¥äº‚ç¢¼ (mojibake)
        replacement_chars = content.count('\ufffd')
        if replacement_chars > 50:
            result['issues'].append(f"ç™¼ç¾äº‚ç¢¼å­—ç¬¦ ({replacement_chars} å€‹)")
            result['passed'] = False
        
        # 4. æª¢æŸ¥é‡è¤‡å…§å®¹
        lines = content.split('\n')
        non_empty_lines = [l.strip() for l in lines if l.strip() and len(l.strip()) > 20]
        if len(non_empty_lines) > 10:
            unique_lines = set(non_empty_lines)
            duplicate_ratio = 1 - (len(unique_lines) / len(non_empty_lines))
            if duplicate_ratio > 0.5:
                result['issues'].append(f"é‡è¤‡å…§å®¹éå¤š ({duplicate_ratio:.0%})")
                result['passed'] = False
        
        # 5. æª¢æŸ¥æ®µè½æ ¼å¼
        paragraphs = re.split(r'\n\n+', content)
        very_long_paragraphs = [p for p in paragraphs if len(p) > 5000]
        if len(very_long_paragraphs) > 3:
            result['issues'].append(f"æ®µè½éé•· ({len(very_long_paragraphs)} å€‹è¶…é•·æ®µè½)")
        
        # 6. æª¢æŸ¥å…ƒæ•¸æ“šé ­
        has_metadata = content.startswith('# ') and '**åŸå§‹æ ¼å¼**' in content[:500]
        if not has_metadata:
            result['issues'].append("ç¼ºå°‘æ¨™æº–å…ƒæ•¸æ“šé ­")
        
        # 7. æª¢æŸ¥ç« ç¯€çµæ§‹ (å°æ–¼å°èªªé¡)
        chapter_patterns = [
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+[ç« èŠ‚å›å·]',
            r'Chapter\s+\d+',
        ]
        has_chapters = any(re.search(p, content) for p in chapter_patterns)
        chapter_headers = len(re.findall(r'^##+ .*(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+[ç« èŠ‚å›å·]|Chapter)', content, re.MULTILINE))
        
        if has_chapters and chapter_headers == 0:
            result['issues'].append("ç« ç¯€æœªæ­£ç¢ºæ ¼å¼åŒ–ç‚ºæ¨™é¡Œ")
        
        return result
    
    def validate_recent_files(self, hours: int = 24):
        """Validate files modified in the last N hours"""
        cutoff = datetime.now() - timedelta(hours=hours)
        
        logger.info(f"ğŸ” æª¢æŸ¥æœ€è¿‘ {hours} å°æ™‚å…§ä¿®æ”¹çš„ Markdown æ–‡ä»¶...")
        
        md_files = list(self.output_dir.glob("*.md"))
        recent_files = []
        
        for f in md_files:
            mtime = datetime.fromtimestamp(f.stat().st_mtime)
            if mtime > cutoff:
                recent_files.append(f)
        
        logger.info(f"æ‰¾åˆ° {len(recent_files)} å€‹æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶")
        
        for filepath in recent_files:
            result = self.validate_file(filepath)
            if result['passed']:
                self.passed.append(result)
            else:
                self.issues.append(result)
        
        return self.generate_report()
    
    def validate_all_files(self, limit: int = None):
        """Validate all Markdown files"""
        md_files = list(self.output_dir.glob("*.md"))
        if limit:
            md_files = md_files[:limit]
        
        logger.info(f"ğŸ” æª¢æŸ¥ {len(md_files)} å€‹ Markdown æ–‡ä»¶...")
        
        for filepath in md_files:
            result = self.validate_file(filepath)
            if result['passed']:
                self.passed.append(result)
            else:
                self.issues.append(result)
        
        return self.generate_report()
    
    def generate_report(self) -> dict:
        """Generate validation report"""
        report = {
            'total_checked': len(self.passed) + len(self.issues),
            'passed': len(self.passed),
            'failed': len(self.issues),
            'pass_rate': len(self.passed) / max(1, len(self.passed) + len(self.issues)),
            'issues': self.issues
        }
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š Markdown è³ªé‡é©—è­‰å ±å‘Š")
        logger.info("=" * 60)
        logger.info(f"ç¸½æª¢æŸ¥æ–‡ä»¶: {report['total_checked']}")
        logger.info(f"âœ… é€šé: {report['passed']}")
        logger.info(f"âŒ å•é¡Œ: {report['failed']}")
        logger.info(f"é€šéç‡: {report['pass_rate']:.1%}")
        
        if self.issues:
            logger.info("\nâš ï¸ å•é¡Œæ–‡ä»¶è©³æƒ…:")
            logger.info("-" * 60)
            for item in self.issues[:20]:
                logger.info(f"\nğŸ“„ {item['file']}")
                for issue in item['issues']:
                    logger.info(f"   âŒ {issue}")
            
            if len(self.issues) > 20:
                logger.info(f"\n... é‚„æœ‰ {len(self.issues) - 20} å€‹å•é¡Œæ–‡ä»¶")
        
        return report


def fix_markdown_structure(filepath: Path) -> bool:
    """å˜—è©¦ä¿®å¾© Markdown çµæ§‹å•é¡Œ"""
    import re
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except:
        return False
    
    original_content = content
    
    # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ¨™é¡Œ
    has_h1 = bool(re.search(r'^# .+', content, re.MULTILINE))
    has_h2 = bool(re.search(r'^## .+', content, re.MULTILINE))
    
    if has_h1 or has_h2:
        return False  # å·²æœ‰æ¨™é¡Œçµæ§‹ï¼Œä¸éœ€ä¿®å¾©
    
    lines = content.split('\n')
    new_lines = []
    
    # ç« ç¯€æ¨¡å¼
    chapter_patterns = [
        (r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+[ç« å·éƒ¨])', '## '),
        (r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+[èŠ‚å›ç¯‡])', '### '),
        (r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.])', '## '),
        (r'^(\d+[ã€\.])', '### '),
        (r'^(åº|åºè¨€|å‰è¨€|åè®°|è·‹|å¼•è¨€|ç®€ä»‹|ä½œè€…ç®€ä»‹)$', '## '),
    ]
    
    # æ‰¾åˆ°ç¬¬ä¸€å€‹éç©ºè¡Œä½œç‚ºæ¨™é¡Œ
    title_added = False
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # è·³éå…ƒæ•¸æ“šé ­
        if stripped.startswith('# ') and '**åŸå§‹æ ¼å¼**' in '\n'.join(lines[i:i+5]):
            new_lines.append(line)
            continue
        
        # æ·»åŠ æ›¸åæ¨™é¡Œ
        if not title_added and stripped and len(stripped) < 30:
            if not any(c in stripped for c in 'ã€‚ï¼Œã€ï¼›ï¼š'):
                if not stripped.startswith('#'):
                    new_lines.append(f"# {stripped}")
                    title_added = True
                    continue
        
        # æª¢æŸ¥ç« ç¯€æ¨™é¡Œ
        matched = False
        for pattern, prefix in chapter_patterns:
            if re.match(pattern, stripped):
                if not stripped.startswith('#'):
                    new_lines.append(f"{prefix}{stripped}")
                    matched = True
                    break
        
        if not matched:
            new_lines.append(line)
    
    new_content = '\n'.join(new_lines)
    
    if new_content != original_content:
        # å‚™ä»½åŸæ–‡ä»¶
        backup_path = filepath.with_suffix('.md.bak')
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(original_content)
        
        # å¯«å…¥ä¿®å¾©å¾Œçš„å…§å®¹
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        logger.info(f"âœ… å·²ä¿®å¾©: {filepath.name}")
        return True
    
    return False


if __name__ == "__main__":
    validator = MarkdownQualityValidator()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == '--recent':
            hours = int(sys.argv[2]) if len(sys.argv) > 2 else 24
            report = validator.validate_recent_files(hours=hours)
        elif sys.argv[1] == '--fix':
            # ä¿®å¾©æ¨¡å¼
            logger.info("ğŸ”§ ä¿®å¾©æ¨¡å¼: å˜—è©¦ä¿®å¾©ç¼ºå°‘æ¨™é¡Œçµæ§‹çš„æ–‡ä»¶...")
            report = validator.validate_recent_files(hours=48)
            fixed_count = 0
            for item in validator.issues:
                if 'ç¼ºå°‘æ¨™é¡Œçµæ§‹' in str(item['issues']):
                    if fix_markdown_structure(Path(item['path'])):
                        fixed_count += 1
            logger.info(f"\nâœ… å·²ä¿®å¾© {fixed_count} å€‹æ–‡ä»¶")
        else:
            report = validator.validate_all_files(limit=100)
    else:
        report = validator.validate_recent_files(hours=24)
