#!/usr/bin/env python3
"""æ™ºèƒ½ç™¾åº¦ç¶²ç›¤è™•ç†å™¨ - åˆ†å±¤è™•ç†ç­–ç•¥"""
import os
import subprocess
from pathlib import Path
from typing import List, Dict
import logging
from dedup_processor import DedupProcessor
from main import EbookConverterPipeline
from multi_cloud_downloader import MultiCloudDownloader

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SmartBaiduProcessor:
    """æ™ºèƒ½ç™¾åº¦ç¶²ç›¤è™•ç†å™¨ - åˆ†å±¤è™•ç†"""
    
    def __init__(self, cache_dir="/home/sms/ebook-converter/data/baidu-cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.dedup = DedupProcessor()
        self.converter = EbookConverterPipeline()
        self.downloader = MultiCloudDownloader(cache_dir=str(self.cache_dir))
        
        # Level 1: å„ªå…ˆè™•ç†æ ¼å¼ï¼ˆçˆ½æ–‡/å°èªªï¼‰- å¿«é€Ÿè™•ç†
        self.priority_formats = ['.txt', '.epub', '.mobi', '.azw', '.azw3']
        
        # Level 2: æ¨™æº–æ–‡æª”æ ¼å¼
        self.standard_formats = ['.doc', '.docx', '.rtf', '.odt', '.md', '.html', '.htm']
        
        # Level 3: å¤ç±æ ¼å¼ï¼ˆåƒ…å»ºç«‹å…ƒæ•¸æ“šç´¢å¼•ï¼Œä¸å…¨æ–‡è™•ç†ï¼‰
        self.archive_formats = ['.pdf', '.djvu', '.fb2', '.pdg']
    
    def list_files_by_level(self, remote_path="/", level=1, _depth=0) -> List[Dict]:
        """æŒ‰å±¤ç´šåˆ—å‡ºæ–‡ä»¶ï¼ˆæ·±åº¦éæ­¸æƒæï¼‰"""
        indent = "  " * _depth
        logger.info(f"{indent}ğŸ“‚ æƒæ: {remote_path}")
        
        # é¸æ“‡æ ¼å¼ï¼ˆåªåœ¨æ ¹å±¤ç´šé¡¯ç¤ºï¼‰
        if _depth == 0:
            if level == 1:
                formats = self.priority_formats
                logger.info(f"Level 1 æ ¼å¼: {formats} (å„ªå…ˆè™•ç†)")
            elif level == 2:
                formats = self.standard_formats
                logger.info(f"Level 2 æ ¼å¼: {formats} (æ¨™æº–è™•ç†)")
            else:
                formats = self.archive_formats
                logger.info(f"Level 3 æ ¼å¼: {formats} (å…ƒæ•¸æ“šç´¢å¼•)")
        else:
            if level == 1:
                formats = self.priority_formats
            elif level == 2:
                formats = self.standard_formats
            else:
                formats = self.archive_formats
        
        all_files = []
        
        try:
            result = subprocess.run(
                ["bypy", "list", remote_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            subdirs = []
            current_files = []
            lines = result.stdout.strip().split('\n')
            
            for line in lines:
                line = line.strip()
                if not line or line.startswith('/apps/bypy') or '($t $f $s $m $d)' in line:
                    continue
                
                parts = line.split()
                if len(parts) < 2:
                    continue
                
                file_type = parts[0]
                filename = parts[1]
                
                # ç›®éŒ„ï¼šè¨˜éŒ„å¾…éæ­¸
                if file_type == 'D':
                    subdir_path = f"{remote_path}/{filename}".replace('//', '/')
                    subdirs.append((filename, subdir_path))
                    continue
                
                # æ–‡ä»¶ï¼šæª¢æŸ¥æ ¼å¼
                if file_type == 'F':
                    ext = os.path.splitext(filename)[1].lower()
                    if ext in formats:
                        size = int(parts[2]) if len(parts) > 2 and parts[2].isdigit() else 0
                        current_files.append({
                            'source': 'baidu',
                            'path': remote_path,
                            'name': filename,
                            'full_path': f"{remote_path}/{filename}".replace('//', '/'),
                            'size': size,
                            'ext': ext,
                            'level': level
                        })
            
            # é¡¯ç¤ºç•¶å‰å±¤ç´šçµæœ
            if current_files:
                logger.info(f"{indent}  âœ“ æ‰¾åˆ° {len(current_files)} å€‹æ–‡ä»¶")
                all_files.extend(current_files)
            
            if subdirs:
                logger.info(f"{indent}  ğŸ“ ç™¼ç¾ {len(subdirs)} å€‹å­ç›®éŒ„ï¼Œé–‹å§‹éæ­¸...")
            
            # é—œéµï¼šéæ­¸æƒææ‰€æœ‰å­ç›®éŒ„
            for subdir_name, subdir_path in subdirs:
                logger.info(f"{indent}  â¤· é€²å…¥: {subdir_name}")
                try:
                    subfiles = self.list_files_by_level(subdir_path, level, _depth + 1)
                    all_files.extend(subfiles)
                except Exception as e:
                    logger.warning(f"{indent}  âœ— ç„¡æ³•æƒæ {subdir_name}: {e}")
            
            # ç¸½çµç•¶å‰å±¤ç´š
            if _depth == 0 and all_files:
                logger.info(f"\n{'='*80}")
                logger.info(f"ğŸ“Š æƒæå®Œæˆ: å…±æ‰¾åˆ° {len(all_files)} å€‹ Level {level} æ–‡ä»¶")
                logger.info(f"{'='*80}\n")
            
            return all_files
            
        except subprocess.TimeoutExpired:
            logger.error(f"{indent}âœ— æƒæè¶…æ™‚: {remote_path}")
            return []
        except Exception as e:
            logger.error(f"{indent}âœ— æƒæå¤±æ•— {remote_path}: {e}")
            return []
    
    def download_file(self, file_info: Dict) -> str:
        """ä¸‹è¼‰æ–‡ä»¶åˆ°æœ¬åœ°ç·©å­˜"""
        # ç¢ºä¿æœ‰ source å­—æ®µ
        if 'source' not in file_info:
            file_info['source'] = 'baidu'
            
        return self.downloader.download_file(file_info)
    
    def create_metadata_index(self, files: List[Dict]) -> str:
        """ç‚º Level 3 æ–‡ä»¶å‰µå»ºå…ƒæ•¸æ“šç´¢å¼•"""
        logger.info(f"å‰µå»ºå…ƒæ•¸æ“šç´¢å¼•: {len(files)} å€‹æ–‡ä»¶")
        
        index_file = Path("/home/sms/ebook-converter/data/baidu-metadata-index.md")
        
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write("# ç™¾åº¦ç¶²ç›¤å¤ç±æ–¹å¿—å…ƒæ•¸æ“šç´¢å¼•\n\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {os.popen('date').read().strip()}\n\n")
            f.write(f"ç¸½æ–‡ä»¶æ•¸: {len(files)}\n\n")
            f.write("---\n\n")
            
            # æŒ‰è·¯å¾‘åˆ†çµ„
            by_path = {}
            for file_info in files:
                path = file_info['path']
                if path not in by_path:
                    by_path[path] = []
                by_path[path].append(file_info)
            
            # å¯«å…¥ç´¢å¼•
            for path in sorted(by_path.keys()):
                f.write(f"## {path}\n\n")
                for file_info in by_path[path]:
                    size_mb = file_info['size'] / 1024 / 1024
                    f.write(f"- **{file_info['name']}** ({size_mb:.1f} MB)\n")
                    f.write(f"  - è·¯å¾‘: `{file_info['full_path']}`\n")
                    f.write(f"  - æ ¼å¼: {file_info['ext']}\n\n")
        
        logger.info(f"å…ƒæ•¸æ“šç´¢å¼•å·²ä¿å­˜: {index_file}")
        return str(index_file)
    
    def process_level(self, remote_path="/", level=1, max_files=None):
        """è™•ç†æŒ‡å®šå±¤ç´šçš„æ–‡ä»¶"""
        logger.info("=" * 80)
        logger.info(f"ğŸš€ æ™ºèƒ½è™•ç†å™¨å•Ÿå‹• - Level {level}")
        logger.info("=" * 80)
        
        # 1. æƒææ–‡ä»¶
        logger.info(f"\næ­¥é©Ÿ 1: æƒæ Level {level} æ–‡ä»¶...")
        all_files = self.list_files_by_level(remote_path, level)
        
        if not all_files:
            logger.warning(f"æœªæ‰¾åˆ° Level {level} æ–‡ä»¶")
            return
        
        logger.info(f"æ‰¾åˆ° {len(all_files)} å€‹ Level {level} æ–‡ä»¶")
        
        # 2. Level 3 ç‰¹æ®Šè™•ç†ï¼šåªå»ºç«‹å…ƒæ•¸æ“šç´¢å¼•
        if level == 3:
            logger.info("\næ­¥é©Ÿ 2: Level 3 æ–‡ä»¶ - å‰µå»ºå…ƒæ•¸æ“šç´¢å¼•...")
            index_file = self.create_metadata_index(all_files)
            logger.info(f"âœ“ å…ƒæ•¸æ“šç´¢å¼•å·²å‰µå»º: {index_file}")
            return
        
        # 3. Level 1/2: å»é‡
        logger.info("\næ­¥é©Ÿ 2: éæ¿¾å·²è™•ç†çš„æ–‡ä»¶...")
        new_files = self.dedup.filter_new_files(all_files)
        
        if not new_files:
            logger.info("æ‰€æœ‰æ–‡ä»¶éƒ½å·²è™•ç†éï¼")
            return
        
        logger.info(f"éœ€è¦è™•ç† {len(new_files)} å€‹æ–°æ–‡ä»¶")
        
        # é™åˆ¶è™•ç†æ•¸é‡
        if max_files:
            new_files = new_files[:max_files]
            logger.info(f"é™åˆ¶è™•ç†æ•¸é‡: {len(new_files)} å€‹æ–‡ä»¶")
        
        # 4. ä¸‹è¼‰ä¸¦è½‰æ›
        logger.info("\næ­¥é©Ÿ 3: ä¸‹è¼‰ä¸¦è½‰æ›ç‚º Markdown...")
        
        stats = {'success': 0, 'failed': 0}
        
        for i, file_info in enumerate(new_files, 1):
            logger.info(f"\nè™•ç† {i}/{len(new_files)}: {file_info['name']}")
            
            try:
                # ä¸‹è¼‰
                local_path = self.download_file(file_info)
                if not local_path:
                    stats['failed'] += 1
                    continue
                
                # è½‰æ›
                success = self.converter.process_single_file(local_path)
                
                if success:
                    stats['success'] += 1
                    logger.info(f"âœ“ æˆåŠŸ: {file_info['name']}")
                else:
                    stats['failed'] += 1
                    logger.error(f"âœ— å¤±æ•—: {file_info['name']}")
                
                # æ¸…ç†ç·©å­˜
                try:
                    os.remove(local_path)
                except:
                    pass
                    
            except Exception as e:
                logger.error(f"è™•ç†ç•°å¸¸ {file_info['name']}: {e}")
                stats['failed'] += 1
        
        # 5. ç¸½çµ
        logger.info("\n" + "=" * 80)
        logger.info(f"ğŸ“Š Level {level} è™•ç†ç¸½çµ")
        logger.info("=" * 80)
        logger.info(f"âœ… æˆåŠŸ: {stats['success']} å€‹")
        logger.info(f"âŒ å¤±æ•—: {stats['failed']} å€‹")
        logger.info(f"ğŸ“ è¼¸å‡ºç›®éŒ„: /home/sms/ebook-converter/data/markdown-output/")
        logger.info("=" * 80)


def main():
    """ä¸»ç¨‹åº"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ™ºèƒ½ç™¾åº¦ç¶²ç›¤è™•ç†å™¨ï¼ˆåˆ†å±¤è™•ç†ï¼‰')
    parser.add_argument('-p', '--path', default='/', help='ç™¾åº¦ç¶²ç›¤è·¯å¾‘')
    parser.add_argument('-l', '--level', type=int, default=1, choices=[1, 2, 3],
                        help='è™•ç†å±¤ç´š: 1=å„ªå…ˆ(TXT/EPUB), 2=æ¨™æº–(DOC/HTML), 3=å¤ç±(PDF/DJVU,åƒ…ç´¢å¼•)')
    parser.add_argument('-n', '--num', type=int, default=None, help='è™•ç†æ–‡ä»¶æ•¸é‡')
    
    args = parser.parse_args()
    
    processor = SmartBaiduProcessor()
    processor.process_level(remote_path=args.path, level=args.level, max_files=args.num)


if __name__ == "__main__":
    main()
