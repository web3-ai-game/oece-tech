# ğŸ§ª ä½æˆæœ¬AIçŸ¥è­˜è’¸é¤¾æ–¹æ¡ˆ - Windsurf + Gemini æ··åˆæ¶æ§‹

**ä¾†æº**: https://www.notion.so/7a52f4428e57443893c7a800de896b28
**æ›´æ–°æ™‚é–“**: 2025-11-21

## ğŸ’¡ æ ¸å¿ƒæ€è·¯

åˆ©ç”¨**å»‰åƒ¹æ¨¡å‹å¤§é‡ä¸¦ç™¼**è™•ç† + **çŸ¥è­˜è’¸é¤¾** + **æœ¬åœ°åŒ–éƒ¨ç½²**,å¯¦ç¾ä½æˆæœ¬çš„AIè‡ªå‹•åŒ–ç³»çµ±ã€‚

> **æˆæœ¬ç›®æ¨™**: å–®æ¬¡æ±ºç­–æˆæœ¬å¾ $0.5 é™è‡³ $0.01-0.03 (é™ä½95%+)

## ğŸ“Š æˆæœ¬åˆ†æå°æ¯”

### Gemini API æˆæœ¬(æ¨è–¦æ–¹æ¡ˆ)

| æ¨¡å‹ | è¼¸å…¥æˆæœ¬ | è¼¸å‡ºæˆæœ¬ | å…è²»é¡åº¦ | ä»˜è²»é™åˆ¶ |
|------|----------|----------|----------|----------|
| Gemini 2.5 Flash | $0.075/M tokens | $0.30/M tokens | 5 RPM / 25 RPD | 5000 RPM |
| Gemini 1.5 Flash | $0.075/M tokens | $0.30/M tokens | 15 RPM / 1500 RPD | æ›´ä¾¿å®œ |
| æœ¬åœ°æ¨¡å‹(è’¸é¤¾å¾Œ) | $0 | $0 | ç„¡é™åˆ¶ | åƒ…ç¡¬ä»¶é™åˆ¶ |

**æˆæœ¬è¨ˆç®—ç¤ºä¾‹**:
```
å–®æ¬¡ä»»å‹™: 500 tokens è¼¸å…¥ + 2000 tokens è¼¸å‡º
æˆæœ¬ = (500 Ã— $0.075 + 2000 Ã— $0.30) / 1,000,000
     = $0.000638 â‰ˆ $0.0006/æ¬¡
```

## ğŸ¯ æ¨è–¦æ¶æ§‹: ä¸‰éšæ®µè’¸é¤¾æ–¹æ¡ˆ

### Phase 1: æ•¸æ“šç”Ÿæˆ(ä½¿ç”¨Gemini API)

**ç›®æ¨™**: ç”¨ä¾¿å®œçš„ Gemini Flash ç”Ÿæˆè¨“ç·´æ•¸æ“š

```python
import google.generativeai as genai

# é…ç½® Gemini API
genai.configure(api_key='YOUR_API_KEY')
model = genai.GenerativeModel('gemini-2.5-flash')

# æ‰¹é‡ç”Ÿæˆè¨“ç·´æ•¸æ“š
async def generate_training_data(prompts, role):
    results = []
    for prompt in prompts:
        response = await model.generate_content_async(
            f"ä½ æ˜¯{role}ã€‚ä»»å‹™:{prompt}"
        )
        results.append({
            "input": prompt,
            "output": response.text,
            "role": role
        })
    return results
```

**æˆæœ¬ä¼°ç®—**:
- 1000å€‹æ¨£æœ¬ Ã— æ¯å€‹3000 tokens = 300è¬ tokens
- æˆæœ¬: 300è¬ Ã— ($0.075 + $0.30) / 1,000,000 = **$1.125**
- **ä¸€æ¬¡æ€§æŠ•è³‡,æ°¸ä¹…å…è²»ä½¿ç”¨!**

### Phase 2: æœ¬åœ°æ¨¡å‹è’¸é¤¾

**æ¨è–¦æ¨¡å‹**:
1. Llama 3.1 8B (å…è²»,8GBé¡¯å­˜å¯è·‘)
2. Qwen 2.5 7B/14B (ä¸­æ–‡æ›´å¥½)
3. Mistral 7B (æ¨ç†å¿«)

**ç¡¬ä»¶éœ€æ±‚**:
- 16GB RAM + 8GB VRAM (RTX 3060å³å¯)
- æˆ–ä½¿ç”¨ Google Colab å…è²»è¨“ç·´ (T4 GPU)

### Phase 3: æ··åˆæ¨ç†æ¶æ§‹

```
ç”¨æˆ¶è«‹æ±‚
    â†“
æª¢æŸ¥æœ¬åœ°ç·©å­˜(å…è²»)â†’ å‘½ä¸­ â†’ ç›´æ¥è¿”å›
    â†“ æœªå‘½ä¸­
ä¸¦ç™¼å•Ÿå‹• 4 å€‹æœ¬åœ°å°æ¨¡å‹(å…è²»,<2ç§’)
    â”œâ”€ ç¡¬ä»¶å°ˆå®¶æ¨¡å‹
    â”œâ”€ é«’è©±Grokæ¨¡å‹  
    â”œâ”€ å¾‹å¸«Grokæ¨¡å‹
    â””â”€ å‘é‡çŸ¥è­˜æ¨¡å‹
    â†“
Gemini Flash åšæœ€çµ‚æ±ºç­–($0.0006/æ¬¡)
    â†“
å­˜å…¥å‘é‡æ•¸æ“šåº«(Qdrant Lite)
    â†“
è¿”å›çµæœ + è¨˜éŒ„æ—¥èªŒ
```

## ğŸš€ é«˜ä¸¦ç™¼å„ªåŒ–ç­–ç•¥

### 1. Gemini API ä¸¦ç™¼é™åˆ¶çªç ´

**å…è²»å±¤é™åˆ¶**:
- æ¯åˆ†é˜ 5 æ¬¡è«‹æ±‚ (RPM)
- æ¯æ—¥ 25 æ¬¡è«‹æ±‚ (RPD)

**ä»˜è²»å±¤é™åˆ¶(Tier 1,æœ€ä½é–€æª»)**:
- æ¯åˆ†é˜ 150 æ¬¡è«‹æ±‚
- æ¯åˆ†é˜ 200è¬ tokens
- æ¯æ—¥ 1000 æ¬¡è«‹æ±‚

**ç ´è§£æ–¹æ³•**:
```python
import asyncio
from asyncio import Semaphore

class GeminiRateLimiter:
    def __init__(self, rpm=150, tpm=2000000):
        self.rpm_semaphore = Semaphore(rpm)
        self.tpm_budget = tpm
        
    async def call_api(self, prompt, tokens_estimate):
        async with self.rpm_semaphore:
            # ç­‰å¾… token é ç®—
            while self.tpm_budget < tokens_estimate:
                await asyncio.sleep(0.1)
            
            self.tpm_budget -= tokens_estimate
            response = await model.generate_content_async(prompt)
            
            # æ¯åˆ†é˜é‡ç½®
            asyncio.create_task(self.reset_budget())
            return response
```

### 2. å‘é‡ç›¸ä¼¼åº¦ç·©å­˜

```python
from sentence_transformers import SentenceTransformer

class VectorCache:
    def __init__(self):
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        self.cache = {}
        
    def find_similar(self, query, threshold=0.85):
        query_vec = self.encoder.encode(query)
        
        for cached_vec, result in self.cache.items():
            similarity = cosine_similarity(query_vec, cached_vec)
            if similarity > threshold:
                return result
        return None
```

**æ•ˆæœ**:
- 30-50% ç·©å­˜å‘½ä¸­ç‡
- ç¸½æˆæœ¬å†é™ 30-50%

## ğŸ’° æœ€çµ‚æˆæœ¬å°æ¯”

| æ–¹æ¡ˆ | åˆæœŸæŠ•è³‡ | å–®æ¬¡æˆæœ¬ | æ¯æ—¥å¯è·‘æ¬¡æ•¸ | ç¸½æˆæœ¬/æœˆ |
|------|----------|----------|-------------|----------|
| ç´”Gemini API(å…è²»å±¤) | $0 | $0 | 25æ¬¡ | $0 |
| ç´”Gemini API(ä»˜è²»Tier 1) | $0 | $0.0006 | ç„¡é™åˆ¶* | ~$20 |
| æ··åˆæ–¹æ¡ˆ(æ¨è–¦) | $1-2(ä¸€æ¬¡æ€§) | $0.0001 | 10,000+ | $3-5 |
| ç´”æœ¬åœ°æ¨¡å‹(è’¸é¤¾å¾Œ) | $1-2(ä¸€æ¬¡æ€§) | $0 | ç„¡é™åˆ¶ | $0(åƒ…é›»è²») |

> **çµè«–**: æ··åˆæ–¹æ¡ˆæ€§åƒ¹æ¯”æœ€é«˜,åˆæœŸæŠ•è³‡$2,æœˆæˆæœ¬<$5,å¯è™•ç†è¬æ¬¡è«‹æ±‚!

## ğŸ“ ç¡¬ä»¶æœ€å„ªè§£çŸ¥è­˜åº«

### ç¡¬ä»¶é…ç½®æ¨è–¦

**æœ¬åœ°é–‹ç™¼æ©Ÿ(æœ€ä½é…ç½®)**:
```
CPU: Intel i5-12400 / AMD Ryzen 5 5600
RAM: 16GB DDR4
GPU: RTX 3060 12GB (æˆ–æ›´é«˜)
SSD: 500GB NVMe
æˆæœ¬: ~$800
```

**é›²ç«¯æ–¹æ¡ˆ(æŒ‰éœ€ä»˜è²»)**:
```
Google Colab Pro: $10/æœˆ,å¯ç”¨ T4/A100 GPU
GCP Cloud Run: æŒ‰ä½¿ç”¨é‡è¨ˆè²»,é©åˆç”Ÿç”¢ç’°å¢ƒ
Modal Labs: æŒ‰ç§’è¨ˆè²»GPU,é©åˆæ‰¹é‡è¨“ç·´
```

## ğŸ“ è¡Œå‹•æ¸…å–®

### ä»Šå¤©å°±èƒ½åš
- [ ] ç”³è«‹ Gemini API Key (å…è²»)
- [ ] æº–å‚™ 100 å€‹æ¸¬è©¦æç¤ºè©
- [ ] è¨­ç½® Python é–‹ç™¼ç’°å¢ƒ

### æœ¬é€±å®Œæˆ
- [ ] ç”¨ Gemini Flash ç”Ÿæˆ 1000 å€‹è¨“ç·´æ¨£æœ¬
- [ ] ä¸‹è¼‰ Llama 3.1 8B åŸºç¤æ¨¡å‹
- [ ] å®Œæˆç¬¬ä¸€å€‹è§’è‰²æ¨¡å‹çš„å¾®èª¿

### å…©é€±å…§éƒ¨ç½²
- [ ] è¨“ç·´å®Œæˆ 4 å€‹å°ˆæ¥­è§’è‰²æ¨¡å‹
- [ ] éƒ¨ç½²æ··åˆæ¨ç†æœå‹™
- [ ] å¯¦ç¾å‘é‡ç·©å­˜ç³»çµ±
- [ ] å£“åŠ›æ¸¬è©¦ä¸¦å„ªåŒ–

## âš¡ ç¸½çµ

**æœ€ä½³æ–¹æ¡ˆ**:
1. ç”¨ Gemini 2.5 Flash API ($0.0006/æ¬¡) ç”Ÿæˆè¨“ç·´æ•¸æ“š
2. è’¸é¤¾åˆ°æœ¬åœ° Llama 3.1 8B æ¨¡å‹ (å…è²»ä½¿ç”¨)
3. æ··åˆæ¶æ§‹: æœ¬åœ°è™•ç† + Gemini æœ€çµ‚æ±ºç­–
4. **ç¸½æˆæœ¬**: åˆæœŸ$2,æœˆé‹è¡Œ<$5

**æ ¸å¿ƒå„ªå‹¢**:
- âœ… æˆæœ¬é™ä½ 95%+
- âœ… é«˜ä¸¦ç™¼èƒ½åŠ› (5000 RPM)
- âœ… å®Œå…¨å¯æ§çš„æœ¬åœ°éƒ¨ç½²
- âœ… çŸ¥è­˜ç”¢æ¬Šä¿è­·

**é–‹å§‹è¡Œå‹•** â†’ å…ˆç”¨å…è²»çš„ Gemini API æ¸¬è©¦æ¦‚å¿µ,é©—è­‰å¯è¡Œæ€§å¾Œå†æŠ•å…¥$2é€²è¡Œè’¸é¤¾!
