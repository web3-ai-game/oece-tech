---
source: github-repos-distill_markdown_gcp-distilled-knowledge_notion-sms_03-賽博宇宙觀_04-zhuge-legion-architecture.md.distilled.md
distilled_at: 2026-02-14T09:35:55.202Z
model: grok-4-1-fast-non-reasoning
---

# 諸葛亮軍團系統知識文檔

## 系統概述

**諸葛亮軍團系統**（Zhuge Liang Legion System）是一個先進的AI決策支持平台，專為複雜決策場景設計。它利用多代理協作機制，生成基於**納什均衡**（Nash Equilibrium）的優化解決方案。納什均衡是一種遊戲理論概念，指在非合作博弈中，各參與方選擇策略後，無人能單方面改變策略以改善自身收益，從而達到穩定狀態。

系統的核心理念是模擬「軍團」式多角度推理：透過5個併發運行的AI Agent，從不同視角剖析問題，確保決策方案兼顧理想性、風險、現實性、多樣性和均衡性。這使得系統適用於商業策略、投資決策、風險管理、產品開發等領域，提供高效、低成本的AI驅動洞察。

### 核心功能：5個併發AI Agent推理流程
系統並行啟動以下5個AI Agent，每個專注特定角色，形成閉環決策管道：

| Agent名稱     | 角色與功能描述                                                                 |
|---------------|-------------------------------------------------------------------------------|
| **理想方案** | 生成最優化、理想化的解決方案，忽略現實約束，作為基準參考。                     |
| **紅隊攻擊** | 模擬攻擊者視角，識別方案漏洞、風險點和潛在失敗模式，提供壓力測試。             |
| **現實評估** | 評估方案在真實環境中的可行性，考慮資源、時間、市場等因素，量化成功概率。       |
| **盲盒變異** | 引入隨機變異和創意發散，生成多樣化替代方案，避免單一思維盲區（類似黑盒優化）。 |
| **納什仲裁** | 整合前4個Agent輸出，計算納什均衡點，仲裁最終推薦方案，確保多方利益平衡。     |

這些Agent的併發推理大幅提升效率，通常在數秒至數分鐘內完成完整決策循環。

## 架構與模型

系統採用**混合AI模型架構**，結合本地高效推理與雲端高性能仲裁，實現成本與性能的最佳平衡：

- **本地核心推理**：使用**Yi-6B INT8量化模型**（基於llama.cpp引擎），支援零成本併發多Agent推理。INT8量化將模型壓縮至高效狀態，適合Mac等資源受限設備，推理速度達每秒20-50 token。
- **雲端最終仲裁**：整合**Google Gemini 1.5 Pro API**，處理複雜納什均衡計算和最終輸出合成，提升準確性和上下文理解（支援超長上下文達100萬token）。

此架構**降低95%成本**，相較純雲端方案（如全Gemini），避免了高頻API調用費用，同時保留頂級模型的仲裁能力。

**架構圖示**（文字描述）：
```
用戶輸入 → 5併發本地Yi-6B Agent → 輸出聚合 → Gemini 1.5 Pro仲裁 → 納什均衡方案
                          ↓
                    SQLite緩存 + Qdrant向量搜索
```

## 成本數據

諸葛亮軍團系統高度經濟，針對高頻使用優化：

- **單次決策成本**：$0.02–$0.05（主要來自Gemini API少量調用；本地Yi-6B免費）。
- **月成本預計**：<$30（假設每日100次決策，視API定價浮動）。
- **成本優化脈絡**：本地推理佔90%工作負荷，僅最終仲裁上雲；無需GPU伺服器，Mac M系列晶片即可流暢運行。

| 使用情境          | 預估月成本 | 備註                  |
|-------------------|------------|-----------------------|
| 個人每日10次     | <$5       | 幾乎全本地            |
| 團隊每日100次    | <$30      | 標準雲輔助            |
| 高頻企業級（1000次）| <$200     | 可擴展優化            |

## 技術棧

系統基於輕量、高性能技術棧，強調可移植性和低依賴：

| 類別         | 技術工具                  | 功能與優勢                          |
|--------------|---------------------------|-------------------------------------|
| **語言與引擎** | Go語言 + llama.cpp      | Go提供高併發服務端；llama.cpp實現高效本地LLM推理（支援多模型）。 |
| **存儲**     | SQLite                    | 輕量級嵌入式資料庫，用於決策歷史緩存和元數據存儲（無外部依賴）。 |
| **搜索**     | Qdrant Lite               | 向量資料庫，用於相似決策檢索和知識增強（本地模式，記憶體佔用<500MB）。 |

- **依賴最小化**：無需Python生態，Go單二進位檔部署。
- **擴展性**：支援自訂Agent提示工程和模型替換。

## 部署方案

系統支援多種部署模式，從個人到雲端無縫切換：

1. **Mac本地運行**（推薦入門）：
   - 下載預編譯二進位檔，單指令啟動：`./zhuge-legion serve`。
   - 硬體需求：Apple Silicon Mac（M1+），8GB RAM即可。
   - 優勢：零成本、離線運行、隱私安全。

2. **Docker容器化**：
   - Dockerfile一鍵構建：包含llama.cpp、Qdrant和SQLite。
   - 指令：`docker run -p 8080:8080 zhuge-legion:latest`。
   - 跨平台（Mac/Linux/Windows），易於CI/CD。

3. **雲部署（GCP Cloud Run）**：
   - 無伺服器模式，按需擴展。
   - 部署步驟：`gcloud run deploy zhuge-legion --image gcr.io/project/zhuge-legion`。
   - 優勢：自動 scaling，高可用；月費<$10（低流量）。

**API介面**：RESTful HTTP（`/decide`端點），支援JSON輸入/輸出，便於整合LangChain、Streamlit等工具。

## 使用案例與擴展

- **典型應用**：商業談判策略（模擬對手紅隊）、投資組合優化（納什均衡分配）、產品迭代（盲盒變異創意）。
- **擴展建議**：自訂Agent提示、整合外部工具（如Wolfram Alpha計算）、多語言支援。
- **限制與注意**：本地模型準確率略低於純雲端（~85% vs 95%）；高併發需監控Gemini配額。

此文檔基於提供事實，歡迎貢獻更新。版本1.0，更新日期：2024。